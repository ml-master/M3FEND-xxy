
lr: 0.0001; model name: eann; batchsize: 64; epoch: 50; gpu: 1; domain_num: 3
{'lr': [0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001]}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [03:44<00:00,  1.15s/it]
Training Epoch 1; Loss 1.2442821493515608; 
100%|███████████████████████████████████████████| 63/63 [00:58<00:00,  1.07it/s]
curent {'gossipcop': {'precision': 0.8956, 'recall': 0.8736, 'fscore': 0.8838, 'auc': 0.9643, 'acc': 0.9157}, 'politifact': {'precision': 0.8104, 'recall': 0.7701, 'fscore': 0.7708, 'auc': 0.893, 'acc': 0.7817}, 'COVID': {'precision': 0.9065, 'recall': 0.8117, 'fscore': 0.8471, 'auc': 0.9536, 'acc': 0.9067}, 'auc': 0.9572312983950914, 'metric': 0.8695893404593205, 'recall': 0.850782359403049, 'precision': 0.8945255056531907, 'acc': 0.908137793310035}
Max {'gossipcop': {'precision': 0.8956, 'recall': 0.8736, 'fscore': 0.8838, 'auc': 0.9643, 'acc': 0.9157}, 'politifact': {'precision': 0.8104, 'recall': 0.7701, 'fscore': 0.7708, 'auc': 0.893, 'acc': 0.7817}, 'COVID': {'precision': 0.9065, 'recall': 0.8117, 'fscore': 0.8471, 'auc': 0.9536, 'acc': 0.9067}, 'auc': 0.9572312983950914, 'metric': 0.8695893404593205, 'recall': 0.850782359403049, 'precision': 0.8945255056531907, 'acc': 0.908137793310035}
100%|█████████████████████████████████████████| 195/195 [03:43<00:00,  1.15s/it]
Training Epoch 2; Loss 1.2514777886561856; 
100%|███████████████████████████████████████████| 63/63 [01:19<00:00,  1.26s/it]
curent {'gossipcop': {'precision': 0.9325, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9791, 'acc': 0.9339}, 'politifact': {'precision': 0.7786, 'recall': 0.7333, 'fscore': 0.7311, 'auc': 0.8956, 'acc': 0.7465}, 'COVID': {'precision': 0.931, 'recall': 0.8375, 'fscore': 0.8734, 'auc': 0.9622, 'acc': 0.9221}, 'auc': 0.9711767877716153, 'metric': 0.8897593410431781, 'recall': 0.8644535541087266, 'precision': 0.9258833106341677, 'acc': 0.9236145781328008}
Max {'gossipcop': {'precision': 0.9325, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9791, 'acc': 0.9339}, 'politifact': {'precision': 0.7786, 'recall': 0.7333, 'fscore': 0.7311, 'auc': 0.8956, 'acc': 0.7465}, 'COVID': {'precision': 0.931, 'recall': 0.8375, 'fscore': 0.8734, 'auc': 0.9622, 'acc': 0.9221}, 'auc': 0.9711767877716153, 'metric': 0.8897593410431781, 'recall': 0.8644535541087266, 'precision': 0.9258833106341677, 'acc': 0.9236145781328008}
100%|█████████████████████████████████████████| 195/195 [04:26<00:00,  1.37s/it]
Training Epoch 3; Loss 1.1677132322238035; 
100%|███████████████████████████████████████████| 63/63 [01:24<00:00,  1.34s/it]
curent {'gossipcop': {'precision': 0.93, 'recall': 0.8901, 'fscore': 0.9078, 'auc': 0.9825, 'acc': 0.9343}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.8992, 'acc': 0.7817}, 'COVID': {'precision': 0.9241, 'recall': 0.8715, 'fscore': 0.8943, 'auc': 0.9671, 'acc': 0.9318}, 'auc': 0.9763173847225571, 'metric': 0.8980964090388772, 'recall': 0.878294215363181, 'precision': 0.9239822408268796, 'acc': 0.9281078382426361}
Max {'gossipcop': {'precision': 0.93, 'recall': 0.8901, 'fscore': 0.9078, 'auc': 0.9825, 'acc': 0.9343}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.8992, 'acc': 0.7817}, 'COVID': {'precision': 0.9241, 'recall': 0.8715, 'fscore': 0.8943, 'auc': 0.9671, 'acc': 0.9318}, 'auc': 0.9763173847225571, 'metric': 0.8980964090388772, 'recall': 0.878294215363181, 'precision': 0.9239822408268796, 'acc': 0.9281078382426361}
100%|█████████████████████████████████████████| 195/195 [04:36<00:00,  1.42s/it]
Training Epoch 4; Loss 0.9788884960688082; 
100%|███████████████████████████████████████████| 63/63 [01:24<00:00,  1.34s/it]
curent {'gossipcop': {'precision': 0.9336, 'recall': 0.9134, 'fscore': 0.9229, 'auc': 0.9845, 'acc': 0.9438}, 'politifact': {'precision': 0.7955, 'recall': 0.7474, 'fscore': 0.746, 'auc': 0.9092, 'acc': 0.7606}, 'COVID': {'precision': 0.9327, 'recall': 0.8855, 'fscore': 0.9063, 'auc': 0.9706, 'acc': 0.9391}, 'auc': 0.9791631500683224, 'metric': 0.9104617385438099, 'recall': 0.8956471210781556, 'precision': 0.9283924950926691, 'acc': 0.935846230654019}
Max {'gossipcop': {'precision': 0.9336, 'recall': 0.9134, 'fscore': 0.9229, 'auc': 0.9845, 'acc': 0.9438}, 'politifact': {'precision': 0.7955, 'recall': 0.7474, 'fscore': 0.746, 'auc': 0.9092, 'acc': 0.7606}, 'COVID': {'precision': 0.9327, 'recall': 0.8855, 'fscore': 0.9063, 'auc': 0.9706, 'acc': 0.9391}, 'auc': 0.9791631500683224, 'metric': 0.9104617385438099, 'recall': 0.8956471210781556, 'precision': 0.9283924950926691, 'acc': 0.935846230654019}
100%|█████████████████████████████████████████| 195/195 [04:38<00:00,  1.43s/it]
Training Epoch 5; Loss 1.1020265884888474; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]
curent {'gossipcop': {'precision': 0.9359, 'recall': 0.9208, 'fscore': 0.928, 'auc': 0.9852, 'acc': 0.9472}, 'politifact': {'precision': 0.7351, 'recall': 0.7069, 'fscore': 0.7051, 'auc': 0.8731, 'acc': 0.7183}, 'COVID': {'precision': 0.9241, 'recall': 0.8815, 'fscore': 0.9005, 'auc': 0.9726, 'acc': 0.9351}, 'auc': 0.9790385620126999, 'metric': 0.9103610417483274, 'recall': 0.8980297001848726, 'precision': 0.9248108650077478, 'acc': 0.9353469795307039}
Max {'gossipcop': {'precision': 0.9336, 'recall': 0.9134, 'fscore': 0.9229, 'auc': 0.9845, 'acc': 0.9438}, 'politifact': {'precision': 0.7955, 'recall': 0.7474, 'fscore': 0.746, 'auc': 0.9092, 'acc': 0.7606}, 'COVID': {'precision': 0.9327, 'recall': 0.8855, 'fscore': 0.9063, 'auc': 0.9706, 'acc': 0.9391}, 'auc': 0.9791631500683224, 'metric': 0.9104617385438099, 'recall': 0.8956471210781556, 'precision': 0.9283924950926691, 'acc': 0.935846230654019}
100%|█████████████████████████████████████████| 195/195 [04:34<00:00,  1.41s/it]
Training Epoch 6; Loss 1.115995409549811; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]
curent {'gossipcop': {'precision': 0.9401, 'recall': 0.9161, 'fscore': 0.9273, 'auc': 0.983, 'acc': 0.9472}, 'politifact': {'precision': 0.7617, 'recall': 0.7191, 'fscore': 0.7161, 'auc': 0.8823, 'acc': 0.7324}, 'COVID': {'precision': 0.9252, 'recall': 0.8984, 'fscore': 0.9109, 'auc': 0.973, 'acc': 0.9407}, 'auc': 0.977704264126678, 'metric': 0.9131897793642181, 'recall': 0.8995217426251909, 'precision': 0.9294607601717688, 'acc': 0.9375936095856215}
Max {'gossipcop': {'precision': 0.9401, 'recall': 0.9161, 'fscore': 0.9273, 'auc': 0.983, 'acc': 0.9472}, 'politifact': {'precision': 0.7617, 'recall': 0.7191, 'fscore': 0.7161, 'auc': 0.8823, 'acc': 0.7324}, 'COVID': {'precision': 0.9252, 'recall': 0.8984, 'fscore': 0.9109, 'auc': 0.973, 'acc': 0.9407}, 'auc': 0.977704264126678, 'metric': 0.9131897793642181, 'recall': 0.8995217426251909, 'precision': 0.9294607601717688, 'acc': 0.9375936095856215}
100%|█████████████████████████████████████████| 195/195 [04:37<00:00,  1.42s/it]
Training Epoch 7; Loss 1.0784716120133027; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]
curent {'gossipcop': {'precision': 0.9348, 'recall': 0.9098, 'fscore': 0.9214, 'auc': 0.983, 'acc': 0.943}, 'politifact': {'precision': 0.7955, 'recall': 0.7474, 'fscore': 0.746, 'auc': 0.8821, 'acc': 0.7606}, 'COVID': {'precision': 0.9403, 'recall': 0.8857, 'fscore': 0.9094, 'auc': 0.971, 'acc': 0.9416}, 'auc': 0.977860669024462, 'metric': 0.9103092390397451, 'recall': 0.8934380274897515, 'precision': 0.931290807200571, 'acc': 0.9360958562156765}
Max {'gossipcop': {'precision': 0.9401, 'recall': 0.9161, 'fscore': 0.9273, 'auc': 0.983, 'acc': 0.9472}, 'politifact': {'precision': 0.7617, 'recall': 0.7191, 'fscore': 0.7161, 'auc': 0.8823, 'acc': 0.7324}, 'COVID': {'precision': 0.9252, 'recall': 0.8984, 'fscore': 0.9109, 'auc': 0.973, 'acc': 0.9407}, 'auc': 0.977704264126678, 'metric': 0.9131897793642181, 'recall': 0.8995217426251909, 'precision': 0.9294607601717688, 'acc': 0.9375936095856215}
100%|█████████████████████████████████████████| 195/195 [04:34<00:00,  1.41s/it]
Training Epoch 8; Loss 1.0418695972515988; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.32s/it]
curent {'gossipcop': {'precision': 0.9374, 'recall': 0.9292, 'fscore': 0.9332, 'auc': 0.9841, 'acc': 0.9506}, 'politifact': {'precision': 0.7728, 'recall': 0.7428, 'fscore': 0.7428, 'auc': 0.8889, 'acc': 0.7535}, 'COVID': {'precision': 0.9296, 'recall': 0.9145, 'fscore': 0.9218, 'auc': 0.9719, 'acc': 0.9472}, 'auc': 0.9785998245049968, 'metric': 0.9215062539081602, 'recall': 0.9143725048897462, 'precision': 0.9292966093461577, 'acc': 0.9425861208187718}
Max {'gossipcop': {'precision': 0.9374, 'recall': 0.9292, 'fscore': 0.9332, 'auc': 0.9841, 'acc': 0.9506}, 'politifact': {'precision': 0.7728, 'recall': 0.7428, 'fscore': 0.7428, 'auc': 0.8889, 'acc': 0.7535}, 'COVID': {'precision': 0.9296, 'recall': 0.9145, 'fscore': 0.9218, 'auc': 0.9719, 'acc': 0.9472}, 'auc': 0.9785998245049968, 'metric': 0.9215062539081602, 'recall': 0.9143725048897462, 'precision': 0.9292966093461577, 'acc': 0.9425861208187718}
100%|█████████████████████████████████████████| 195/195 [04:36<00:00,  1.42s/it]
Training Epoch 9; Loss 0.9438439246935716; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]
curent {'gossipcop': {'precision': 0.9236, 'recall': 0.9433, 'fscore': 0.9329, 'auc': 0.9822, 'acc': 0.9487}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.916, 'acc': 0.8099}, 'COVID': {'precision': 0.9345, 'recall': 0.9192, 'fscore': 0.9266, 'auc': 0.9751, 'acc': 0.9505}, 'auc': 0.9784142820780751, 'metric': 0.925777999667166, 'recall': 0.9291037028105994, 'precision': 0.9225835933730202, 'acc': 0.9443334997503744}
Max {'gossipcop': {'precision': 0.9236, 'recall': 0.9433, 'fscore': 0.9329, 'auc': 0.9822, 'acc': 0.9487}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.916, 'acc': 0.8099}, 'COVID': {'precision': 0.9345, 'recall': 0.9192, 'fscore': 0.9266, 'auc': 0.9751, 'acc': 0.9505}, 'auc': 0.9784142820780751, 'metric': 0.925777999667166, 'recall': 0.9291037028105994, 'precision': 0.9225835933730202, 'acc': 0.9443334997503744}
100%|█████████████████████████████████████████| 195/195 [04:36<00:00,  1.42s/it]
Training Epoch 10; Loss 1.028271813881703; 
100%|███████████████████████████████████████████| 63/63 [01:24<00:00,  1.34s/it]
curent {'gossipcop': {'precision': 0.909, 'recall': 0.9457, 'fscore': 0.9251, 'auc': 0.9845, 'acc': 0.9415}, 'politifact': {'precision': 0.7893, 'recall': 0.7907, 'fscore': 0.7886, 'auc': 0.9044, 'acc': 0.7887}, 'COVID': {'precision': 0.9244, 'recall': 0.913, 'fscore': 0.9185, 'auc': 0.9756, 'acc': 0.9448}, 'auc': 0.9789111271869891, 'metric': 0.9179254532948942, 'recall': 0.9307421027248614, 'precision': 0.9069919115971747, 'acc': 0.9370943584623065}
Max {'gossipcop': {'precision': 0.9236, 'recall': 0.9433, 'fscore': 0.9329, 'auc': 0.9822, 'acc': 0.9487}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.916, 'acc': 0.8099}, 'COVID': {'precision': 0.9345, 'recall': 0.9192, 'fscore': 0.9266, 'auc': 0.9751, 'acc': 0.9505}, 'auc': 0.9784142820780751, 'metric': 0.925777999667166, 'recall': 0.9291037028105994, 'precision': 0.9225835933730202, 'acc': 0.9443334997503744}
100%|█████████████████████████████████████████| 195/195 [04:34<00:00,  1.41s/it]
Training Epoch 11; Loss 0.9074814475499666; 
100%|███████████████████████████████████████████| 63/63 [01:23<00:00,  1.33s/it]
curent {'gossipcop': {'precision': 0.9251, 'recall': 0.9408, 'fscore': 0.9325, 'auc': 0.9811, 'acc': 0.9487}, 'politifact': {'precision': 0.8464, 'recall': 0.8232, 'fscore': 0.826, 'auc': 0.9257, 'acc': 0.831}, 'COVID': {'precision': 0.9266, 'recall': 0.9021, 'fscore': 0.9136, 'auc': 0.9721, 'acc': 0.9424}, 'auc': 0.9770113267958095, 'metric': 0.92290649008573, 'recall': 0.9231934731934732, 'precision': 0.9226205128753986, 'acc': 0.9425861208187718}
Max {'gossipcop': {'precision': 0.9236, 'recall': 0.9433, 'fscore': 0.9329, 'auc': 0.9822, 'acc': 0.9487}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.916, 'acc': 0.8099}, 'COVID': {'precision': 0.9345, 'recall': 0.9192, 'fscore': 0.9266, 'auc': 0.9751, 'acc': 0.9505}, 'auc': 0.9784142820780751, 'metric': 0.925777999667166, 'recall': 0.9291037028105994, 'precision': 0.9225835933730202, 'acc': 0.9443334997503744}
100%|█████████████████████████████████████████| 195/195 [04:36<00:00,  1.42s/it]
Training Epoch 12; Loss 0.9194404247479561; 
100%|███████████████████████████████████████████| 63/63 [01:24<00:00,  1.34s/it]
curent {'gossipcop': {'precision': 0.9279, 'recall': 0.9336, 'fscore': 0.9307, 'auc': 0.9829, 'acc': 0.9479}, 'politifact': {'precision': 0.784, 'recall': 0.758, 'fscore': 0.7589, 'auc': 0.898, 'acc': 0.7676}, 'COVID': {'precision': 0.9401, 'recall': 0.8907, 'fscore': 0.9124, 'auc': 0.9702, 'acc': 0.9432}, 'auc': 0.976279204511963, 'metric': 0.9182666935075816, 'recall': 0.9120361439326956, 'precision': 0.9250003454517819, 'acc': 0.9400898652021967}
Max {'gossipcop': {'precision': 0.9236, 'recall': 0.9433, 'fscore': 0.9329, 'auc': 0.9822, 'acc': 0.9487}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.916, 'acc': 0.8099}, 'COVID': {'precision': 0.9345, 'recall': 0.9192, 'fscore': 0.9266, 'auc': 0.9751, 'acc': 0.9505}, 'auc': 0.9784142820780751, 'metric': 0.925777999667166, 'recall': 0.9291037028105994, 'precision': 0.9225835933730202, 'acc': 0.9443334997503744}
100%|███████████████████████████████████████████| 64/64 [01:25<00:00,  1.33s/it]
{'gossipcop': {'precision': 0.9223, 'recall': 0.9397, 'fscore': 0.9306, 'auc': 0.9813, 'acc': 0.9488}, 'politifact': {'precision': 0.8047, 'recall': 0.7972, 'fscore': 0.7964, 'auc': 0.8946, 'acc': 0.7977}, 'COVID': {'precision': 0.9301, 'recall': 0.9161, 'fscore': 0.9229, 'auc': 0.9845, 'acc': 0.9481}, 'auc': 0.9794920500914591, 'metric': 0.9216258481867788, 'recall': 0.9236561725910583, 'precision': 0.9196440263085905, 'acc': 0.9421426820299093}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:35<00:00,  1.41s/it]
Training Epoch 1; Loss 1.2319137606865318; 
100%|███████████████████████████████████████████| 63/63 [01:24<00:00,  1.34s/it]
curent {'gossipcop': {'precision': 0.9279, 'recall': 0.8153, 'fscore': 0.8538, 'auc': 0.9712, 'acc': 0.9043}, 'politifact': {'precision': 0.7804, 'recall': 0.6924, 'fscore': 0.679, 'auc': 0.8903, 'acc': 0.7113}, 'COVID': {'precision': 0.9162, 'recall': 0.7212, 'fscore': 0.7683, 'auc': 0.9558, 'acc': 0.875}, 'auc': 0.9619629651957238, 'metric': 0.8237119853919788, 'recall': 0.7820455885111057, 'precision': 0.9184326544646189, 'acc': 0.8884173739390914}
Max {'gossipcop': {'precision': 0.9279, 'recall': 0.8153, 'fscore': 0.8538, 'auc': 0.9712, 'acc': 0.9043}, 'politifact': {'precision': 0.7804, 'recall': 0.6924, 'fscore': 0.679, 'auc': 0.8903, 'acc': 0.7113}, 'COVID': {'precision': 0.9162, 'recall': 0.7212, 'fscore': 0.7683, 'auc': 0.9558, 'acc': 0.875}, 'auc': 0.9619629651957238, 'metric': 0.8237119853919788, 'recall': 0.7820455885111057, 'precision': 0.9184326544646189, 'acc': 0.8884173739390914}
100%|█████████████████████████████████████████| 195/195 [04:29<00:00,  1.38s/it]
Training Epoch 2; Loss 1.1866972324175722; 
100%|███████████████████████████████████████████| 63/63 [01:20<00:00,  1.28s/it]
curent {'gossipcop': {'precision': 0.9228, 'recall': 0.9045, 'fscore': 0.9131, 'auc': 0.9823, 'acc': 0.9366}, 'politifact': {'precision': 0.805, 'recall': 0.7797, 'fscore': 0.7814, 'auc': 0.8839, 'acc': 0.7887}, 'COVID': {'precision': 0.9207, 'recall': 0.8454, 'fscore': 0.8758, 'auc': 0.9615, 'acc': 0.9221}, 'auc': 0.9735278849502986, 'metric': 0.8974616168360456, 'recall': 0.881536519036519, 'precision': 0.9172025408474741, 'acc': 0.9268597104343484}
Max {'gossipcop': {'precision': 0.9228, 'recall': 0.9045, 'fscore': 0.9131, 'auc': 0.9823, 'acc': 0.9366}, 'politifact': {'precision': 0.805, 'recall': 0.7797, 'fscore': 0.7814, 'auc': 0.8839, 'acc': 0.7887}, 'COVID': {'precision': 0.9207, 'recall': 0.8454, 'fscore': 0.8758, 'auc': 0.9615, 'acc': 0.9221}, 'auc': 0.9735278849502986, 'metric': 0.8974616168360456, 'recall': 0.881536519036519, 'precision': 0.9172025408474741, 'acc': 0.9268597104343484}
100%|█████████████████████████████████████████| 195/195 [04:28<00:00,  1.37s/it]
Training Epoch 3; Loss 1.1416474247590092; 
100%|███████████████████████████████████████████| 63/63 [01:21<00:00,  1.29s/it]
curent {'gossipcop': {'precision': 0.9339, 'recall': 0.9021, 'fscore': 0.9166, 'auc': 0.9849, 'acc': 0.94}, 'politifact': {'precision': 0.789, 'recall': 0.7484, 'fscore': 0.7478, 'auc': 0.896, 'acc': 0.7606}, 'COVID': {'precision': 0.9119, 'recall': 0.8264, 'fscore': 0.8596, 'auc': 0.9687, 'acc': 0.9131}, 'auc': 0.9777447887361681, 'metric': 0.8936718263637491, 'recall': 0.8723993917959435, 'precision': 0.9221859239338233, 'acc': 0.9253619570644034}
Max {'gossipcop': {'precision': 0.9228, 'recall': 0.9045, 'fscore': 0.9131, 'auc': 0.9823, 'acc': 0.9366}, 'politifact': {'precision': 0.805, 'recall': 0.7797, 'fscore': 0.7814, 'auc': 0.8839, 'acc': 0.7887}, 'COVID': {'precision': 0.9207, 'recall': 0.8454, 'fscore': 0.8758, 'auc': 0.9615, 'acc': 0.9221}, 'auc': 0.9735278849502986, 'metric': 0.8974616168360456, 'recall': 0.881536519036519, 'precision': 0.9172025408474741, 'acc': 0.9268597104343484}
100%|█████████████████████████████████████████| 195/195 [04:26<00:00,  1.36s/it]
Training Epoch 4; Loss 1.062984833961879; 
100%|███████████████████████████████████████████| 63/63 [01:20<00:00,  1.28s/it]
curent {'gossipcop': {'precision': 0.9327, 'recall': 0.9077, 'fscore': 0.9193, 'auc': 0.9849, 'acc': 0.9415}, 'politifact': {'precision': 0.789, 'recall': 0.7484, 'fscore': 0.7478, 'auc': 0.891, 'acc': 0.7606}, 'COVID': {'precision': 0.9256, 'recall': 0.8277, 'fscore': 0.8646, 'auc': 0.966, 'acc': 0.9172}, 'auc': 0.9761706923344855, 'metric': 0.897151430871179, 'recall': 0.8766055783297162, 'precision': 0.9243143706700074, 'acc': 0.927608587119321}
Max {'gossipcop': {'precision': 0.9228, 'recall': 0.9045, 'fscore': 0.9131, 'auc': 0.9823, 'acc': 0.9366}, 'politifact': {'precision': 0.805, 'recall': 0.7797, 'fscore': 0.7814, 'auc': 0.8839, 'acc': 0.7887}, 'COVID': {'precision': 0.9207, 'recall': 0.8454, 'fscore': 0.8758, 'auc': 0.9615, 'acc': 0.9221}, 'auc': 0.9735278849502986, 'metric': 0.8974616168360456, 'recall': 0.881536519036519, 'precision': 0.9172025408474741, 'acc': 0.9268597104343484}
100%|█████████████████████████████████████████| 195/195 [04:24<00:00,  1.36s/it]
Training Epoch 5; Loss 0.6936619514074083; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9317, 'recall': 0.9167, 'fscore': 0.9238, 'auc': 0.984, 'acc': 0.9441}, 'politifact': {'precision': 0.7941, 'recall': 0.7646, 'fscore': 0.7655, 'auc': 0.8956, 'acc': 0.7746}, 'COVID': {'precision': 0.9227, 'recall': 0.8391, 'fscore': 0.872, 'auc': 0.97, 'acc': 0.9205}, 'auc': 0.9751883891970098, 'metric': 0.9030609824695723, 'recall': 0.8869031830238727, 'precision': 0.923070880415735, 'acc': 0.9308537194208687}
Max {'gossipcop': {'precision': 0.9317, 'recall': 0.9167, 'fscore': 0.9238, 'auc': 0.984, 'acc': 0.9441}, 'politifact': {'precision': 0.7941, 'recall': 0.7646, 'fscore': 0.7655, 'auc': 0.8956, 'acc': 0.7746}, 'COVID': {'precision': 0.9227, 'recall': 0.8391, 'fscore': 0.872, 'auc': 0.97, 'acc': 0.9205}, 'auc': 0.9751883891970098, 'metric': 0.9030609824695723, 'recall': 0.8869031830238727, 'precision': 0.923070880415735, 'acc': 0.9308537194208687}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 6; Loss 1.177402142378; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9327, 'recall': 0.897, 'fscore': 0.913, 'auc': 0.9836, 'acc': 0.9377}, 'politifact': {'precision': 0.7799, 'recall': 0.759, 'fscore': 0.7602, 'auc': 0.9056, 'acc': 0.7676}, 'COVID': {'precision': 0.9393, 'recall': 0.8496, 'fscore': 0.8847, 'auc': 0.9669, 'acc': 0.9286}, 'auc': 0.9760705530102081, 'metric': 0.8986504030557475, 'recall': 0.877095222784878, 'precision': 0.9275095463359422, 'acc': 0.9288567149276086}
Max {'gossipcop': {'precision': 0.9317, 'recall': 0.9167, 'fscore': 0.9238, 'auc': 0.984, 'acc': 0.9441}, 'politifact': {'precision': 0.7941, 'recall': 0.7646, 'fscore': 0.7655, 'auc': 0.8956, 'acc': 0.7746}, 'COVID': {'precision': 0.9227, 'recall': 0.8391, 'fscore': 0.872, 'auc': 0.97, 'acc': 0.9205}, 'auc': 0.9751883891970098, 'metric': 0.9030609824695723, 'recall': 0.8869031830238727, 'precision': 0.923070880415735, 'acc': 0.9308537194208687}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 7; Loss 1.0735088828282477; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9354, 'recall': 0.9179, 'fscore': 0.9262, 'auc': 0.9822, 'acc': 0.946}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.9038, 'acc': 0.7817}, 'COVID': {'precision': 0.9346, 'recall': 0.896, 'fscore': 0.9135, 'auc': 0.9745, 'acc': 0.9432}, 'auc': 0.9782565375237788, 'metric': 0.9158985835708247, 'recall': 0.9033963641722262, 'precision': 0.9305386214279714, 'acc': 0.9393409885172241}
Max {'gossipcop': {'precision': 0.9354, 'recall': 0.9179, 'fscore': 0.9262, 'auc': 0.9822, 'acc': 0.946}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.9038, 'acc': 0.7817}, 'COVID': {'precision': 0.9346, 'recall': 0.896, 'fscore': 0.9135, 'auc': 0.9745, 'acc': 0.9432}, 'auc': 0.9782565375237788, 'metric': 0.9158985835708247, 'recall': 0.9033963641722262, 'precision': 0.9305386214279714, 'acc': 0.9393409885172241}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 8; Loss 1.0663039638445937; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9304, 'recall': 0.9003, 'fscore': 0.9141, 'auc': 0.9845, 'acc': 0.9381}, 'politifact': {'precision': 0.8132, 'recall': 0.7293, 'fscore': 0.7222, 'auc': 0.8831, 'acc': 0.7465}, 'COVID': {'precision': 0.9395, 'recall': 0.8427, 'fscore': 0.8798, 'auc': 0.9713, 'acc': 0.9261}, 'auc': 0.9764369490662593, 'metric': 0.8964288669028831, 'recall': 0.87355216622458, 'precision': 0.9277068192764432, 'acc': 0.927608587119321}
Max {'gossipcop': {'precision': 0.9354, 'recall': 0.9179, 'fscore': 0.9262, 'auc': 0.9822, 'acc': 0.946}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.9038, 'acc': 0.7817}, 'COVID': {'precision': 0.9346, 'recall': 0.896, 'fscore': 0.9135, 'auc': 0.9745, 'acc': 0.9432}, 'auc': 0.9782565375237788, 'metric': 0.9158985835708247, 'recall': 0.9033963641722262, 'precision': 0.9305386214279714, 'acc': 0.9393409885172241}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 9; Loss 0.9228547817621475; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9276, 'recall': 0.9366, 'fscore': 0.932, 'auc': 0.9834, 'acc': 0.9487}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9064, 'acc': 0.8028}, 'COVID': {'precision': 0.9339, 'recall': 0.8992, 'fscore': 0.9151, 'auc': 0.9738, 'acc': 0.944}, 'auc': 0.977078309621413, 'metric': 0.9215407390598449, 'recall': 0.9181121560431905, 'precision': 0.9251171406777814, 'acc': 0.9420868696954569}
Max {'gossipcop': {'precision': 0.9276, 'recall': 0.9366, 'fscore': 0.932, 'auc': 0.9834, 'acc': 0.9487}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9064, 'acc': 0.8028}, 'COVID': {'precision': 0.9339, 'recall': 0.8992, 'fscore': 0.9151, 'auc': 0.9738, 'acc': 0.944}, 'auc': 0.977078309621413, 'metric': 0.9215407390598449, 'recall': 0.9181121560431905, 'precision': 0.9251171406777814, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 10; Loss 0.940366289860163; 
100%|███████████████████████████████████████████| 63/63 [01:13<00:00,  1.17s/it]
curent {'gossipcop': {'precision': 0.9369, 'recall': 0.9356, 'fscore': 0.9363, 'auc': 0.9838, 'acc': 0.9525}, 'politifact': {'precision': 0.7887, 'recall': 0.757, 'fscore': 0.7575, 'auc': 0.9048, 'acc': 0.7676}, 'COVID': {'precision': 0.94, 'recall': 0.8788, 'fscore': 0.9049, 'auc': 0.9706, 'acc': 0.9391}, 'auc': 0.9777015848136538, 'metric': 0.9198843118057078, 'recall': 0.9098039412694585, 'precision': 0.9313109875278159, 'acc': 0.9418372441337993}
Max {'gossipcop': {'precision': 0.9276, 'recall': 0.9366, 'fscore': 0.932, 'auc': 0.9834, 'acc': 0.9487}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9064, 'acc': 0.8028}, 'COVID': {'precision': 0.9339, 'recall': 0.8992, 'fscore': 0.9151, 'auc': 0.9738, 'acc': 0.944}, 'auc': 0.977078309621413, 'metric': 0.9215407390598449, 'recall': 0.9181121560431905, 'precision': 0.9251171406777814, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 11; Loss 0.9574724836227221; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9311, 'recall': 0.9072, 'fscore': 0.9183, 'auc': 0.9817, 'acc': 0.9407}, 'politifact': {'precision': 0.7493, 'recall': 0.7307, 'fscore': 0.7311, 'auc': 0.8861, 'acc': 0.7394}, 'COVID': {'precision': 0.9444, 'recall': 0.8799, 'fscore': 0.9072, 'auc': 0.9701, 'acc': 0.9407}, 'auc': 0.9750694946815637, 'metric': 0.9069454123112659, 'recall': 0.8907623985210191, 'precision': 0.9269370268672096, 'acc': 0.9335996005991013}
Max {'gossipcop': {'precision': 0.9276, 'recall': 0.9366, 'fscore': 0.932, 'auc': 0.9834, 'acc': 0.9487}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9064, 'acc': 0.8028}, 'COVID': {'precision': 0.9339, 'recall': 0.8992, 'fscore': 0.9151, 'auc': 0.9738, 'acc': 0.944}, 'auc': 0.977078309621413, 'metric': 0.9215407390598449, 'recall': 0.9181121560431905, 'precision': 0.9251171406777814, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 12; Loss 0.9402964885418235; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9341, 'recall': 0.9241, 'fscore': 0.9289, 'auc': 0.9822, 'acc': 0.9476}, 'politifact': {'precision': 0.7793, 'recall': 0.7085, 'fscore': 0.7004, 'auc': 0.9062, 'acc': 0.7254}, 'COVID': {'precision': 0.9442, 'recall': 0.8506, 'fscore': 0.8869, 'auc': 0.973, 'acc': 0.9302}, 'auc': 0.9755437330868365, 'metric': 0.9077527080039942, 'recall': 0.8905812099777617, 'precision': 0.9292337221863366, 'acc': 0.9343484772840739}
Max {'gossipcop': {'precision': 0.9276, 'recall': 0.9366, 'fscore': 0.932, 'auc': 0.9834, 'acc': 0.9487}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9064, 'acc': 0.8028}, 'COVID': {'precision': 0.9339, 'recall': 0.8992, 'fscore': 0.9151, 'auc': 0.9738, 'acc': 0.944}, 'auc': 0.977078309621413, 'metric': 0.9215407390598449, 'recall': 0.9181121560431905, 'precision': 0.9251171406777814, 'acc': 0.9420868696954569}
100%|███████████████████████████████████████████| 64/64 [01:16<00:00,  1.19s/it]
{'gossipcop': {'precision': 0.9297, 'recall': 0.9371, 'fscore': 0.9333, 'auc': 0.9822, 'acc': 0.9514}, 'politifact': {'precision': 0.8053, 'recall': 0.7913, 'fscore': 0.7894, 'auc': 0.9016, 'acc': 0.7919}, 'COVID': {'precision': 0.9442, 'recall': 0.9033, 'fscore': 0.9218, 'auc': 0.9833, 'acc': 0.9489}, 'auc': 0.9796707144282903, 'metric': 0.9226473397707553, 'recall': 0.9175701322966875, 'precision': 0.9280414255765199, 'acc': 0.9438587889188527}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 1; Loss 1.1276753804622563; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9092, 'recall': 0.8861, 'fscore': 0.8968, 'auc': 0.9701, 'acc': 0.9252}, 'politifact': {'precision': 0.7952, 'recall': 0.7731, 'fscore': 0.7747, 'auc': 0.8859, 'acc': 0.7817}, 'COVID': {'precision': 0.8991, 'recall': 0.8252, 'fscore': 0.8546, 'auc': 0.9543, 'acc': 0.9091}, 'auc': 0.9613105524743456, 'metric': 0.880429164173486, 'recall': 0.863566701497736, 'precision': 0.9019098224943206, 'acc': 0.9151273090364453}
Max {'gossipcop': {'precision': 0.9092, 'recall': 0.8861, 'fscore': 0.8968, 'auc': 0.9701, 'acc': 0.9252}, 'politifact': {'precision': 0.7952, 'recall': 0.7731, 'fscore': 0.7747, 'auc': 0.8859, 'acc': 0.7817}, 'COVID': {'precision': 0.8991, 'recall': 0.8252, 'fscore': 0.8546, 'auc': 0.9543, 'acc': 0.9091}, 'auc': 0.9613105524743456, 'metric': 0.880429164173486, 'recall': 0.863566701497736, 'precision': 0.9019098224943206, 'acc': 0.9151273090364453}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 2; Loss 1.239435149767461; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9305, 'recall': 0.9123, 'fscore': 0.921, 'auc': 0.981, 'acc': 0.9422}, 'politifact': {'precision': 0.8123, 'recall': 0.7959, 'fscore': 0.798, 'auc': 0.9076, 'acc': 0.8028}, 'COVID': {'precision': 0.9218, 'recall': 0.8541, 'fscore': 0.8821, 'auc': 0.9628, 'acc': 0.9253}, 'auc': 0.9742760831122901, 'metric': 0.9052005902168769, 'recall': 0.8904462395841706, 'precision': 0.9231050081150685, 'acc': 0.9321018472291562}
Max {'gossipcop': {'precision': 0.9305, 'recall': 0.9123, 'fscore': 0.921, 'auc': 0.981, 'acc': 0.9422}, 'politifact': {'precision': 0.8123, 'recall': 0.7959, 'fscore': 0.798, 'auc': 0.9076, 'acc': 0.8028}, 'COVID': {'precision': 0.9218, 'recall': 0.8541, 'fscore': 0.8821, 'auc': 0.9628, 'acc': 0.9253}, 'auc': 0.9742760831122901, 'metric': 0.9052005902168769, 'recall': 0.8904462395841706, 'precision': 0.9231050081150685, 'acc': 0.9321018472291562}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 3; Loss 1.2082056002739139; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9292, 'recall': 0.9379, 'fscore': 0.9335, 'auc': 0.9839, 'acc': 0.9498}, 'politifact': {'precision': 0.8298, 'recall': 0.8186, 'fscore': 0.8207, 'auc': 0.9096, 'acc': 0.8239}, 'COVID': {'precision': 0.9195, 'recall': 0.8919, 'fscore': 0.9047, 'auc': 0.9721, 'acc': 0.9367}, 'auc': 0.9784270088149398, 'metric': 0.9208268102769308, 'recall': 0.9189718806098116, 'precision': 0.9227246477500166, 'acc': 0.9413379930104843}
Max {'gossipcop': {'precision': 0.9292, 'recall': 0.9379, 'fscore': 0.9335, 'auc': 0.9839, 'acc': 0.9498}, 'politifact': {'precision': 0.8298, 'recall': 0.8186, 'fscore': 0.8207, 'auc': 0.9096, 'acc': 0.8239}, 'COVID': {'precision': 0.9195, 'recall': 0.8919, 'fscore': 0.9047, 'auc': 0.9721, 'acc': 0.9367}, 'auc': 0.9784270088149398, 'metric': 0.9208268102769308, 'recall': 0.9189718806098116, 'precision': 0.9227246477500166, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 4; Loss 0.8047152384733542; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9284, 'recall': 0.9103, 'fscore': 0.9189, 'auc': 0.984, 'acc': 0.9407}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.9024, 'acc': 0.8099}, 'COVID': {'precision': 0.9208, 'recall': 0.9037, 'fscore': 0.9119, 'auc': 0.9692, 'acc': 0.9407}, 'auc': 0.9785355209924175, 'metric': 0.9121338582326357, 'recall': 0.9029375318168422, 'precision': 0.922473670607999, 'acc': 0.9360958562156765}
Max {'gossipcop': {'precision': 0.9292, 'recall': 0.9379, 'fscore': 0.9335, 'auc': 0.9839, 'acc': 0.9498}, 'politifact': {'precision': 0.8298, 'recall': 0.8186, 'fscore': 0.8207, 'auc': 0.9096, 'acc': 0.8239}, 'COVID': {'precision': 0.9195, 'recall': 0.8919, 'fscore': 0.9047, 'auc': 0.9721, 'acc': 0.9367}, 'auc': 0.9784270088149398, 'metric': 0.9208268102769308, 'recall': 0.9189718806098116, 'precision': 0.9227246477500166, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 5; Loss 1.0169886176402745; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9345, 'recall': 0.9341, 'fscore': 0.9343, 'auc': 0.9848, 'acc': 0.951}, 'politifact': {'precision': 0.8098, 'recall': 0.7787, 'fscore': 0.7802, 'auc': 0.91, 'acc': 0.7887}, 'COVID': {'precision': 0.9215, 'recall': 0.8792, 'fscore': 0.898, 'auc': 0.9702, 'acc': 0.9334}, 'auc': 0.9787210634193393, 'metric': 0.9176063102332201, 'recall': 0.9098347533692361, 'precision': 0.9261709941369757, 'acc': 0.9398402396405392}
Max {'gossipcop': {'precision': 0.9292, 'recall': 0.9379, 'fscore': 0.9335, 'auc': 0.9839, 'acc': 0.9498}, 'politifact': {'precision': 0.8298, 'recall': 0.8186, 'fscore': 0.8207, 'auc': 0.9096, 'acc': 0.8239}, 'COVID': {'precision': 0.9195, 'recall': 0.8919, 'fscore': 0.9047, 'auc': 0.9721, 'acc': 0.9367}, 'auc': 0.9784270088149398, 'metric': 0.9208268102769308, 'recall': 0.9189718806098116, 'precision': 0.9227246477500166, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 6; Loss 1.026400120136066; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9293, 'recall': 0.906, 'fscore': 0.9168, 'auc': 0.983, 'acc': 0.9396}, 'politifact': {'precision': 0.7077, 'recall': 0.6968, 'fscore': 0.697, 'auc': 0.8743, 'acc': 0.7042}, 'COVID': {'precision': 0.9313, 'recall': 0.8918, 'fscore': 0.9096, 'auc': 0.9684, 'acc': 0.9407}, 'auc': 0.977533457921389, 'metric': 0.9049259810524799, 'recall': 0.8918110146558422, 'precision': 0.9205000632609284, 'acc': 0.9316025961058413}
Max {'gossipcop': {'precision': 0.9292, 'recall': 0.9379, 'fscore': 0.9335, 'auc': 0.9839, 'acc': 0.9498}, 'politifact': {'precision': 0.8298, 'recall': 0.8186, 'fscore': 0.8207, 'auc': 0.9096, 'acc': 0.8239}, 'COVID': {'precision': 0.9195, 'recall': 0.8919, 'fscore': 0.9047, 'auc': 0.9721, 'acc': 0.9367}, 'auc': 0.9784270088149398, 'metric': 0.9208268102769308, 'recall': 0.9189718806098116, 'precision': 0.9227246477500166, 'acc': 0.9413379930104843}
100%|███████████████████████████████████████████| 64/64 [01:15<00:00,  1.18s/it]
{'gossipcop': {'precision': 0.926, 'recall': 0.9324, 'fscore': 0.9291, 'auc': 0.982, 'acc': 0.9484}, 'politifact': {'precision': 0.7945, 'recall': 0.7916, 'fscore': 0.7913, 'auc': 0.8915, 'acc': 0.7919}, 'COVID': {'precision': 0.9359, 'recall': 0.8893, 'fscore': 0.9099, 'auc': 0.9767, 'acc': 0.9416}, 'auc': 0.9772669264825703, 'metric': 0.9169930360559313, 'recall': 0.9124130811090279, 'precision': 0.9218347628352268, 'acc': 0.9396911007599902}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 1; Loss 1.115464650667631; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9099, 'recall': 0.8524, 'fscore': 0.8761, 'auc': 0.9679, 'acc': 0.9138}, 'politifact': {'precision': 0.7734, 'recall': 0.7257, 'fscore': 0.7226, 'auc': 0.8701, 'acc': 0.7394}, 'COVID': {'precision': 0.9245, 'recall': 0.8172, 'fscore': 0.8563, 'auc': 0.9536, 'acc': 0.9131}, 'auc': 0.9609297551107896, 'metric': 0.8640967856827709, 'recall': 0.8356964874206254, 'precision': 0.9083658415851669, 'acc': 0.9073889166250624}
Max {'gossipcop': {'precision': 0.9099, 'recall': 0.8524, 'fscore': 0.8761, 'auc': 0.9679, 'acc': 0.9138}, 'politifact': {'precision': 0.7734, 'recall': 0.7257, 'fscore': 0.7226, 'auc': 0.8701, 'acc': 0.7394}, 'COVID': {'precision': 0.9245, 'recall': 0.8172, 'fscore': 0.8563, 'auc': 0.9536, 'acc': 0.9131}, 'auc': 0.9609297551107896, 'metric': 0.8640967856827709, 'recall': 0.8356964874206254, 'precision': 0.9083658415851669, 'acc': 0.9073889166250624}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 2; Loss 1.2053881574899723; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9306, 'recall': 0.8712, 'fscore': 0.8959, 'auc': 0.9805, 'acc': 0.9274}, 'politifact': {'precision': 0.8124, 'recall': 0.7616, 'fscore': 0.7609, 'auc': 0.8966, 'acc': 0.7746}, 'COVID': {'precision': 0.9335, 'recall': 0.838, 'fscore': 0.8745, 'auc': 0.9596, 'acc': 0.9229}, 'auc': 0.9715800243817484, 'metric': 0.8841325851796148, 'recall': 0.8556788039546661, 'precision': 0.927057597282273, 'acc': 0.9206190713929107}
Max {'gossipcop': {'precision': 0.9306, 'recall': 0.8712, 'fscore': 0.8959, 'auc': 0.9805, 'acc': 0.9274}, 'politifact': {'precision': 0.8124, 'recall': 0.7616, 'fscore': 0.7609, 'auc': 0.8966, 'acc': 0.7746}, 'COVID': {'precision': 0.9335, 'recall': 0.838, 'fscore': 0.8745, 'auc': 0.9596, 'acc': 0.9229}, 'auc': 0.9715800243817484, 'metric': 0.8841325851796148, 'recall': 0.8556788039546661, 'precision': 0.927057597282273, 'acc': 0.9206190713929107}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 3; Loss 1.2238580098518952; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9359, 'recall': 0.9174, 'fscore': 0.9262, 'auc': 0.9842, 'acc': 0.946}, 'politifact': {'precision': 0.8267, 'recall': 0.7843, 'fscore': 0.7856, 'auc': 0.9042, 'acc': 0.7958}, 'COVID': {'precision': 0.9286, 'recall': 0.8438, 'fscore': 0.8772, 'auc': 0.9689, 'acc': 0.9237}, 'auc': 0.9774654703534014, 'metric': 0.906910822867498, 'recall': 0.889231840955979, 'precision': 0.9291914788327988, 'acc': 0.9338492261607588}
Max {'gossipcop': {'precision': 0.9359, 'recall': 0.9174, 'fscore': 0.9262, 'auc': 0.9842, 'acc': 0.946}, 'politifact': {'precision': 0.8267, 'recall': 0.7843, 'fscore': 0.7856, 'auc': 0.9042, 'acc': 0.7958}, 'COVID': {'precision': 0.9286, 'recall': 0.8438, 'fscore': 0.8772, 'auc': 0.9689, 'acc': 0.9237}, 'auc': 0.9774654703534014, 'metric': 0.906910822867498, 'recall': 0.889231840955979, 'precision': 0.9291914788327988, 'acc': 0.9338492261607588}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 4; Loss 0.8267362677133999; 
100%|███████████████████████████████████████████| 63/63 [01:13<00:00,  1.17s/it]
curent {'gossipcop': {'precision': 0.9104, 'recall': 0.9511, 'fscore': 0.9279, 'auc': 0.9837, 'acc': 0.9434}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.918, 'acc': 0.7958}, 'COVID': {'precision': 0.9071, 'recall': 0.8769, 'fscore': 0.8908, 'auc': 0.9687, 'acc': 0.9278}, 'auc': 0.9744803807303807, 'metric': 0.9124020554684937, 'recall': 0.9218092731023766, 'precision': 0.9040479382552911, 'acc': 0.9333499750374439}
Max {'gossipcop': {'precision': 0.9104, 'recall': 0.9511, 'fscore': 0.9279, 'auc': 0.9837, 'acc': 0.9434}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.918, 'acc': 0.7958}, 'COVID': {'precision': 0.9071, 'recall': 0.8769, 'fscore': 0.8908, 'auc': 0.9687, 'acc': 0.9278}, 'auc': 0.9744803807303807, 'metric': 0.9124020554684937, 'recall': 0.9218092731023766, 'precision': 0.9040479382552911, 'acc': 0.9333499750374439}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 5; Loss 1.0794142609987512; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9368, 'recall': 0.9164, 'fscore': 0.926, 'auc': 0.9842, 'acc': 0.946}, 'politifact': {'precision': 0.8267, 'recall': 0.7843, 'fscore': 0.7856, 'auc': 0.9082, 'acc': 0.7958}, 'COVID': {'precision': 0.9316, 'recall': 0.853, 'fscore': 0.8847, 'auc': 0.9715, 'acc': 0.9278}, 'auc': 0.9781265908421082, 'metric': 0.9087017194468598, 'recall': 0.8910785574578678, 'precision': 0.9308645200521894, 'acc': 0.9350973539690465}
Max {'gossipcop': {'precision': 0.9104, 'recall': 0.9511, 'fscore': 0.9279, 'auc': 0.9837, 'acc': 0.9434}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.918, 'acc': 0.7958}, 'COVID': {'precision': 0.9071, 'recall': 0.8769, 'fscore': 0.8908, 'auc': 0.9687, 'acc': 0.9278}, 'auc': 0.9744803807303807, 'metric': 0.9124020554684937, 'recall': 0.9218092731023766, 'precision': 0.9040479382552911, 'acc': 0.9333499750374439}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 6; Loss 1.0054223143137409; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9357, 'recall': 0.8993, 'fscore': 0.9156, 'auc': 0.9855, 'acc': 0.9396}, 'politifact': {'precision': 0.8171, 'recall': 0.7691, 'fscore': 0.7692, 'auc': 0.9052, 'acc': 0.7817}, 'COVID': {'precision': 0.9328, 'recall': 0.843, 'fscore': 0.8779, 'auc': 0.973, 'acc': 0.9245}, 'auc': 0.9796698751440132, 'metric': 0.898968446142298, 'recall': 0.8760697157248881, 'precision': 0.9301985362543881, 'acc': 0.9293559660509236}
Max {'gossipcop': {'precision': 0.9104, 'recall': 0.9511, 'fscore': 0.9279, 'auc': 0.9837, 'acc': 0.9434}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.918, 'acc': 0.7958}, 'COVID': {'precision': 0.9071, 'recall': 0.8769, 'fscore': 0.8908, 'auc': 0.9687, 'acc': 0.9278}, 'auc': 0.9744803807303807, 'metric': 0.9124020554684937, 'recall': 0.9218092731023766, 'precision': 0.9040479382552911, 'acc': 0.9333499750374439}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 7; Loss 1.075935005530333; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.942, 'recall': 0.9407, 'fscore': 0.9414, 'auc': 0.9849, 'acc': 0.9563}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9084, 'acc': 0.8099}, 'COVID': {'precision': 0.9399, 'recall': 0.8957, 'fscore': 0.9154, 'auc': 0.9741, 'acc': 0.9448}, 'auc': 0.9790861198188785, 'metric': 0.9281791520622007, 'recall': 0.9200630308388928, 'precision': 0.9371323078381513, 'acc': 0.9475786320519222}
Max {'gossipcop': {'precision': 0.942, 'recall': 0.9407, 'fscore': 0.9414, 'auc': 0.9849, 'acc': 0.9563}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9084, 'acc': 0.8099}, 'COVID': {'precision': 0.9399, 'recall': 0.8957, 'fscore': 0.9154, 'auc': 0.9741, 'acc': 0.9448}, 'auc': 0.9790861198188785, 'metric': 0.9281791520622007, 'recall': 0.9200630308388928, 'precision': 0.9371323078381513, 'acc': 0.9475786320519222}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 8; Loss 0.9504205605922602; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.937, 'recall': 0.9415, 'fscore': 0.9392, 'auc': 0.9828, 'acc': 0.9544}, 'politifact': {'precision': 0.8009, 'recall': 0.7807, 'fscore': 0.7825, 'auc': 0.8899, 'acc': 0.7887}, 'COVID': {'precision': 0.9382, 'recall': 0.8852, 'fscore': 0.9083, 'auc': 0.9755, 'acc': 0.9407}, 'auc': 0.9774798716609061, 'metric': 0.923975808434335, 'recall': 0.9172293224017363, 'precision': 0.9313031845559268, 'acc': 0.9443334997503744}
Max {'gossipcop': {'precision': 0.942, 'recall': 0.9407, 'fscore': 0.9414, 'auc': 0.9849, 'acc': 0.9563}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9084, 'acc': 0.8099}, 'COVID': {'precision': 0.9399, 'recall': 0.8957, 'fscore': 0.9154, 'auc': 0.9741, 'acc': 0.9448}, 'auc': 0.9790861198188785, 'metric': 0.9281791520622007, 'recall': 0.9200630308388928, 'precision': 0.9371323078381513, 'acc': 0.9475786320519222}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 9; Loss 1.0653527424885672; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9316, 'recall': 0.9458, 'fscore': 0.9384, 'auc': 0.9825, 'acc': 0.9533}, 'politifact': {'precision': 0.7947, 'recall': 0.7953, 'fscore': 0.795, 'auc': 0.8948, 'acc': 0.7958}, 'COVID': {'precision': 0.9348, 'recall': 0.9111, 'fscore': 0.9222, 'auc': 0.9721, 'acc': 0.9481}, 'auc': 0.9773459060096992, 'metric': 0.9278913510221591, 'recall': 0.9299249122524984, 'precision': 0.9259069650777304, 'acc': 0.946080878681977}
Max {'gossipcop': {'precision': 0.942, 'recall': 0.9407, 'fscore': 0.9414, 'auc': 0.9849, 'acc': 0.9563}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9084, 'acc': 0.8099}, 'COVID': {'precision': 0.9399, 'recall': 0.8957, 'fscore': 0.9154, 'auc': 0.9741, 'acc': 0.9448}, 'auc': 0.9790861198188785, 'metric': 0.9281791520622007, 'recall': 0.9200630308388928, 'precision': 0.9371323078381513, 'acc': 0.9475786320519222}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 10; Loss 0.8210698742132921; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.938, 'recall': 0.9054, 'fscore': 0.9202, 'auc': 0.9819, 'acc': 0.9426}, 'politifact': {'precision': 0.7902, 'recall': 0.7847, 'fscore': 0.786, 'auc': 0.8787, 'acc': 0.7887}, 'COVID': {'precision': 0.9483, 'recall': 0.8859, 'fscore': 0.9125, 'auc': 0.9694, 'acc': 0.944}, 'auc': 0.9769898922916165, 'metric': 0.9123454689565549, 'recall': 0.8951112584733274, 'precision': 0.933848795987114, 'acc': 0.9375936095856215}
Max {'gossipcop': {'precision': 0.942, 'recall': 0.9407, 'fscore': 0.9414, 'auc': 0.9849, 'acc': 0.9563}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9084, 'acc': 0.8099}, 'COVID': {'precision': 0.9399, 'recall': 0.8957, 'fscore': 0.9154, 'auc': 0.9741, 'acc': 0.9448}, 'auc': 0.9790861198188785, 'metric': 0.9281791520622007, 'recall': 0.9200630308388928, 'precision': 0.9371323078381513, 'acc': 0.9475786320519222}
100%|███████████████████████████████████████████| 64/64 [01:16<00:00,  1.19s/it]
{'gossipcop': {'precision': 0.9407, 'recall': 0.932, 'fscore': 0.9362, 'auc': 0.9834, 'acc': 0.9544}, 'politifact': {'precision': 0.8004, 'recall': 0.7678, 'fscore': 0.7621, 'auc': 0.8866, 'acc': 0.7688}, 'COVID': {'precision': 0.9443, 'recall': 0.8795, 'fscore': 0.9069, 'auc': 0.9788, 'acc': 0.9407}, 'auc': 0.9780539003471846, 'metric': 0.9188140936629571, 'recall': 0.9049117967545918, 'precision': 0.9352795690452103, 'acc': 0.9423878401569012}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 1; Loss 1.1170832175474905; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9132, 'recall': 0.8403, 'fscore': 0.8689, 'auc': 0.9668, 'acc': 0.9103}, 'politifact': {'precision': 0.7734, 'recall': 0.7257, 'fscore': 0.7226, 'auc': 0.8733, 'acc': 0.7394}, 'COVID': {'precision': 0.8915, 'recall': 0.8299, 'fscore': 0.8554, 'auc': 0.9492, 'acc': 0.9083}, 'auc': 0.9594527838062321, 'metric': 0.8586604775166181, 'recall': 0.8308348739383222, 'precision': 0.9020431420431421, 'acc': 0.9036445332001997}
Max {'gossipcop': {'precision': 0.9132, 'recall': 0.8403, 'fscore': 0.8689, 'auc': 0.9668, 'acc': 0.9103}, 'politifact': {'precision': 0.7734, 'recall': 0.7257, 'fscore': 0.7226, 'auc': 0.8733, 'acc': 0.7394}, 'COVID': {'precision': 0.8915, 'recall': 0.8299, 'fscore': 0.8554, 'auc': 0.9492, 'acc': 0.9083}, 'auc': 0.9594527838062321, 'metric': 0.8586604775166181, 'recall': 0.8308348739383222, 'precision': 0.9020431420431421, 'acc': 0.9036445332001997}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 2; Loss 1.1487046871429836; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9359, 'recall': 0.9174, 'fscore': 0.9262, 'auc': 0.9811, 'acc': 0.946}, 'politifact': {'precision': 0.7896, 'recall': 0.7656, 'fscore': 0.7668, 'auc': 0.8964, 'acc': 0.7746}, 'COVID': {'precision': 0.9242, 'recall': 0.8496, 'fscore': 0.8799, 'auc': 0.9642, 'acc': 0.9245}, 'auc': 0.9739937505023711, 'metric': 0.9066305375708814, 'recall': 0.8905966160276505, 'precision': 0.926403115927007, 'acc': 0.9333499750374439}
Max {'gossipcop': {'precision': 0.9359, 'recall': 0.9174, 'fscore': 0.9262, 'auc': 0.9811, 'acc': 0.946}, 'politifact': {'precision': 0.7896, 'recall': 0.7656, 'fscore': 0.7668, 'auc': 0.8964, 'acc': 0.7746}, 'COVID': {'precision': 0.9242, 'recall': 0.8496, 'fscore': 0.8799, 'auc': 0.9642, 'acc': 0.9245}, 'auc': 0.9739937505023711, 'metric': 0.9066305375708814, 'recall': 0.8905966160276505, 'precision': 0.926403115927007, 'acc': 0.9333499750374439}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 3; Loss 1.140787228407003; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9233, 'recall': 0.9426, 'fscore': 0.9323, 'auc': 0.9846, 'acc': 0.9483}, 'politifact': {'precision': 0.795, 'recall': 0.7963, 'fscore': 0.7953, 'auc': 0.8863, 'acc': 0.7958}, 'COVID': {'precision': 0.9209, 'recall': 0.9119, 'fscore': 0.9163, 'auc': 0.971, 'acc': 0.9432}, 'auc': 0.978621593923318, 'metric': 0.9222477126542528, 'recall': 0.9281321169252204, 'precision': 0.9167721637636626, 'acc': 0.9413379930104843}
Max {'gossipcop': {'precision': 0.9233, 'recall': 0.9426, 'fscore': 0.9323, 'auc': 0.9846, 'acc': 0.9483}, 'politifact': {'precision': 0.795, 'recall': 0.7963, 'fscore': 0.7953, 'auc': 0.8863, 'acc': 0.7958}, 'COVID': {'precision': 0.9209, 'recall': 0.9119, 'fscore': 0.9163, 'auc': 0.971, 'acc': 0.9432}, 'auc': 0.978621593923318, 'metric': 0.9222477126542528, 'recall': 0.9281321169252204, 'precision': 0.9167721637636626, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:03<00:00,  1.25s/it]
Training Epoch 4; Loss 1.06344067958685; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9228, 'recall': 0.9449, 'fscore': 0.933, 'auc': 0.9844, 'acc': 0.9487}, 'politifact': {'precision': 0.8258, 'recall': 0.8014, 'fscore': 0.8038, 'auc': 0.9168, 'acc': 0.8099}, 'COVID': {'precision': 0.937, 'recall': 0.8815, 'fscore': 0.9055, 'auc': 0.9757, 'acc': 0.9391}, 'auc': 0.9770491720922756, 'metric': 0.9203167248666738, 'recall': 0.9193188516464379, 'precision': 0.9213269646174851, 'acc': 0.9408387418871692}
Max {'gossipcop': {'precision': 0.9233, 'recall': 0.9426, 'fscore': 0.9323, 'auc': 0.9846, 'acc': 0.9483}, 'politifact': {'precision': 0.795, 'recall': 0.7963, 'fscore': 0.7953, 'auc': 0.8863, 'acc': 0.7958}, 'COVID': {'precision': 0.9209, 'recall': 0.9119, 'fscore': 0.9163, 'auc': 0.971, 'acc': 0.9432}, 'auc': 0.978621593923318, 'metric': 0.9222477126542528, 'recall': 0.9281321169252204, 'precision': 0.9167721637636626, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 5; Loss 1.0914465399888849; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9272, 'recall': 0.9359, 'fscore': 0.9315, 'auc': 0.9851, 'acc': 0.9483}, 'politifact': {'precision': 0.7587, 'recall': 0.7468, 'fscore': 0.748, 'auc': 0.8821, 'acc': 0.7535}, 'COVID': {'precision': 0.9346, 'recall': 0.896, 'fscore': 0.9135, 'auc': 0.9745, 'acc': 0.9432}, 'auc': 0.9779310009913459, 'metric': 0.918525254153398, 'recall': 0.915263041556145, 'precision': 0.9219224538088613, 'acc': 0.9398402396405392}
Max {'gossipcop': {'precision': 0.9233, 'recall': 0.9426, 'fscore': 0.9323, 'auc': 0.9846, 'acc': 0.9483}, 'politifact': {'precision': 0.795, 'recall': 0.7963, 'fscore': 0.7953, 'auc': 0.8863, 'acc': 0.7958}, 'COVID': {'precision': 0.9209, 'recall': 0.9119, 'fscore': 0.9163, 'auc': 0.971, 'acc': 0.9432}, 'auc': 0.978621593923318, 'metric': 0.9222477126542528, 'recall': 0.9281321169252204, 'precision': 0.9167721637636626, 'acc': 0.9413379930104843}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 6; Loss 1.006222384709578; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.937, 'recall': 0.9343, 'fscore': 0.9356, 'auc': 0.9845, 'acc': 0.9521}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.9124, 'acc': 0.7958}, 'COVID': {'precision': 0.9329, 'recall': 0.9105, 'fscore': 0.9211, 'auc': 0.9734, 'acc': 0.9472}, 'auc': 0.9794253878305603, 'metric': 0.9252877538785398, 'recall': 0.9201015459636148, 'precision': 0.930812114817654, 'acc': 0.945082376435347}
Max {'gossipcop': {'precision': 0.937, 'recall': 0.9343, 'fscore': 0.9356, 'auc': 0.9845, 'acc': 0.9521}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.9124, 'acc': 0.7958}, 'COVID': {'precision': 0.9329, 'recall': 0.9105, 'fscore': 0.9211, 'auc': 0.9734, 'acc': 0.9472}, 'auc': 0.9794253878305603, 'metric': 0.9252877538785398, 'recall': 0.9201015459636148, 'precision': 0.930812114817654, 'acc': 0.945082376435347}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 7; Loss 1.00377885378324; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9418, 'recall': 0.9307, 'fscore': 0.9361, 'auc': 0.9855, 'acc': 0.9529}, 'politifact': {'precision': 0.7995, 'recall': 0.7721, 'fscore': 0.7735, 'auc': 0.8958, 'acc': 0.7817}, 'COVID': {'precision': 0.9486, 'recall': 0.8997, 'fscore': 0.9213, 'auc': 0.9737, 'acc': 0.9489}, 'auc': 0.9804274509015887, 'metric': 0.9247978093138606, 'recall': 0.9133084827050344, 'precision': 0.9380246045943721, 'acc': 0.945581627558662}
Max {'gossipcop': {'precision': 0.937, 'recall': 0.9343, 'fscore': 0.9356, 'auc': 0.9845, 'acc': 0.9521}, 'politifact': {'precision': 0.8032, 'recall': 0.7893, 'fscore': 0.7912, 'auc': 0.9124, 'acc': 0.7958}, 'COVID': {'precision': 0.9329, 'recall': 0.9105, 'fscore': 0.9211, 'auc': 0.9734, 'acc': 0.9472}, 'auc': 0.9794253878305603, 'metric': 0.9252877538785398, 'recall': 0.9201015459636148, 'precision': 0.930812114817654, 'acc': 0.945082376435347}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 8; Loss 0.9242216929411278; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9257, 'recall': 0.9423, 'fscore': 0.9336, 'auc': 0.9828, 'acc': 0.9495}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.892, 'acc': 0.8028}, 'COVID': {'precision': 0.9448, 'recall': 0.9105, 'fscore': 0.9262, 'auc': 0.9774, 'acc': 0.9513}, 'auc': 0.9767671743964849, 'metric': 0.9257973740266587, 'recall': 0.9253640516571551, 'precision': 0.9262329797134192, 'acc': 0.9448327508736895}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.9423, 'fscore': 0.9336, 'auc': 0.9828, 'acc': 0.9495}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.892, 'acc': 0.8028}, 'COVID': {'precision': 0.9448, 'recall': 0.9105, 'fscore': 0.9262, 'auc': 0.9774, 'acc': 0.9513}, 'auc': 0.9767671743964849, 'metric': 0.9257973740266587, 'recall': 0.9253640516571551, 'precision': 0.9262329797134192, 'acc': 0.9448327508736895}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 9; Loss 0.91962069211862; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9136, 'recall': 0.9459, 'fscore': 0.928, 'auc': 0.9826, 'acc': 0.9441}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.9104, 'acc': 0.8028}, 'COVID': {'precision': 0.9349, 'recall': 0.9161, 'fscore': 0.9251, 'auc': 0.9738, 'acc': 0.9497}, 'auc': 0.9771821330010986, 'metric': 0.9218416171149556, 'recall': 0.9291576239852102, 'precision': 0.9151527669107892, 'acc': 0.9408387418871692}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.9423, 'fscore': 0.9336, 'auc': 0.9828, 'acc': 0.9495}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.892, 'acc': 0.8028}, 'COVID': {'precision': 0.9448, 'recall': 0.9105, 'fscore': 0.9262, 'auc': 0.9774, 'acc': 0.9513}, 'auc': 0.9767671743964849, 'metric': 0.9257973740266587, 'recall': 0.9253640516571551, 'precision': 0.9262329797134192, 'acc': 0.9448327508736895}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 10; Loss 0.9577476507578142; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.8973, 'recall': 0.9414, 'fscore': 0.9158, 'auc': 0.9819, 'acc': 0.9335}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.916, 'acc': 0.8028}, 'COVID': {'precision': 0.919, 'recall': 0.9146, 'fscore': 0.9168, 'auc': 0.9726, 'acc': 0.9432}, 'auc': 0.9738669855049165, 'metric': 0.9113918666296237, 'recall': 0.9255643303057096, 'precision': 0.899547521983231, 'acc': 0.9318522216674987}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.9423, 'fscore': 0.9336, 'auc': 0.9828, 'acc': 0.9495}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.892, 'acc': 0.8028}, 'COVID': {'precision': 0.9448, 'recall': 0.9105, 'fscore': 0.9262, 'auc': 0.9774, 'acc': 0.9513}, 'auc': 0.9767671743964849, 'metric': 0.9257973740266587, 'recall': 0.9253640516571551, 'precision': 0.9262329797134192, 'acc': 0.9448327508736895}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 11; Loss 1.016785091008895; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9207, 'recall': 0.949, 'fscore': 0.9336, 'auc': 0.983, 'acc': 0.9487}, 'politifact': {'precision': 0.7705, 'recall': 0.7524, 'fscore': 0.7535, 'auc': 0.8737, 'acc': 0.7606}, 'COVID': {'precision': 0.9178, 'recall': 0.9222, 'fscore': 0.92, 'auc': 0.975, 'acc': 0.9448}, 'auc': 0.9777647161267852, 'metric': 0.9220439993703888, 'recall': 0.9305146960319374, 'precision': 0.9144075891721604, 'acc': 0.9408387418871692}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.9423, 'fscore': 0.9336, 'auc': 0.9828, 'acc': 0.9495}, 'politifact': {'precision': 0.816, 'recall': 0.7949, 'fscore': 0.797, 'auc': 0.892, 'acc': 0.8028}, 'COVID': {'precision': 0.9448, 'recall': 0.9105, 'fscore': 0.9262, 'auc': 0.9774, 'acc': 0.9513}, 'auc': 0.9767671743964849, 'metric': 0.9257973740266587, 'recall': 0.9253640516571551, 'precision': 0.9262329797134192, 'acc': 0.9448327508736895}
100%|███████████████████████████████████████████| 64/64 [01:15<00:00,  1.18s/it]
{'gossipcop': {'precision': 0.9193, 'recall': 0.9353, 'fscore': 0.9269, 'auc': 0.9827, 'acc': 0.9461}, 'politifact': {'precision': 0.8144, 'recall': 0.8089, 'fscore': 0.8083, 'auc': 0.8834, 'acc': 0.8092}, 'COVID': {'precision': 0.9447, 'recall': 0.8932, 'fscore': 0.9158, 'auc': 0.9823, 'acc': 0.9456}, 'auc': 0.9762436968465418, 'metric': 0.9181284298376711, 'recall': 0.9158304455810027, 'precision': 0.9204910563316434, 'acc': 0.9401814170139741}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 1; Loss 1.1645930470564423; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.918, 'recall': 0.7514, 'fscore': 0.795, 'auc': 0.9675, 'acc': 0.8746}, 'politifact': {'precision': 0.8115, 'recall': 0.6515, 'fscore': 0.6164, 'auc': 0.8924, 'acc': 0.6761}, 'COVID': {'precision': 0.9078, 'recall': 0.6576, 'fscore': 0.6951, 'auc': 0.9521, 'acc': 0.8482}, 'auc': 0.9576305160356885, 'metric': 0.761292087709132, 'recall': 0.7190492457733837, 'precision': 0.9111239552120125, 'acc': 0.8594608087868197}
Max {'gossipcop': {'precision': 0.918, 'recall': 0.7514, 'fscore': 0.795, 'auc': 0.9675, 'acc': 0.8746}, 'politifact': {'precision': 0.8115, 'recall': 0.6515, 'fscore': 0.6164, 'auc': 0.8924, 'acc': 0.6761}, 'COVID': {'precision': 0.9078, 'recall': 0.6576, 'fscore': 0.6951, 'auc': 0.9521, 'acc': 0.8482}, 'auc': 0.9576305160356885, 'metric': 0.761292087709132, 'recall': 0.7190492457733837, 'precision': 0.9111239552120125, 'acc': 0.8594608087868197}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 2; Loss 1.2210630422983406; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9256, 'recall': 0.8554, 'fscore': 0.8834, 'auc': 0.981, 'acc': 0.9198}, 'politifact': {'precision': 0.8219, 'recall': 0.7767, 'fscore': 0.7774, 'auc': 0.8976, 'acc': 0.7887}, 'COVID': {'precision': 0.932, 'recall': 0.8256, 'fscore': 0.8648, 'auc': 0.9626, 'acc': 0.918}, 'auc': 0.9737579709562467, 'metric': 0.873935438991669, 'recall': 0.8428790558100903, 'precision': 0.9236035484351467, 'acc': 0.9146280579131303}
Max {'gossipcop': {'precision': 0.9256, 'recall': 0.8554, 'fscore': 0.8834, 'auc': 0.981, 'acc': 0.9198}, 'politifact': {'precision': 0.8219, 'recall': 0.7767, 'fscore': 0.7774, 'auc': 0.8976, 'acc': 0.7887}, 'COVID': {'precision': 0.932, 'recall': 0.8256, 'fscore': 0.8648, 'auc': 0.9626, 'acc': 0.918}, 'auc': 0.9737579709562467, 'metric': 0.873935438991669, 'recall': 0.8428790558100903, 'precision': 0.9236035484351467, 'acc': 0.9146280579131303}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 3; Loss 1.2078423307492183; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9286, 'recall': 0.9124, 'fscore': 0.9201, 'auc': 0.9841, 'acc': 0.9415}, 'politifact': {'precision': 0.8364, 'recall': 0.7994, 'fscore': 0.8016, 'auc': 0.9104, 'acc': 0.8099}, 'COVID': {'precision': 0.9269, 'recall': 0.8451, 'fscore': 0.8776, 'auc': 0.968, 'acc': 0.9237}, 'auc': 0.9767638252552044, 'metric': 0.9036886802704603, 'recall': 0.8872347480106101, 'precision': 0.9241373883779955, 'acc': 0.9313529705441838}
Max {'gossipcop': {'precision': 0.9286, 'recall': 0.9124, 'fscore': 0.9201, 'auc': 0.9841, 'acc': 0.9415}, 'politifact': {'precision': 0.8364, 'recall': 0.7994, 'fscore': 0.8016, 'auc': 0.9104, 'acc': 0.8099}, 'COVID': {'precision': 0.9269, 'recall': 0.8451, 'fscore': 0.8776, 'auc': 0.968, 'acc': 0.9237}, 'auc': 0.9767638252552044, 'metric': 0.9036886802704603, 'recall': 0.8872347480106101, 'precision': 0.9241373883779955, 'acc': 0.9313529705441838}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 4; Loss 0.9327354822403345; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9246, 'recall': 0.9246, 'fscore': 0.9246, 'auc': 0.9839, 'acc': 0.9438}, 'politifact': {'precision': 0.8364, 'recall': 0.7994, 'fscore': 0.8016, 'auc': 0.9114, 'acc': 0.8099}, 'COVID': {'precision': 0.9318, 'recall': 0.8599, 'fscore': 0.8894, 'auc': 0.9703, 'acc': 0.9302}, 'auc': 0.9756432025828577, 'metric': 0.9100621422335713, 'recall': 0.8993944752565441, 'precision': 0.9222968941279623, 'acc': 0.934847728407389}
Max {'gossipcop': {'precision': 0.9246, 'recall': 0.9246, 'fscore': 0.9246, 'auc': 0.9839, 'acc': 0.9438}, 'politifact': {'precision': 0.8364, 'recall': 0.7994, 'fscore': 0.8016, 'auc': 0.9114, 'acc': 0.8099}, 'COVID': {'precision': 0.9318, 'recall': 0.8599, 'fscore': 0.8894, 'auc': 0.9703, 'acc': 0.9302}, 'auc': 0.9756432025828577, 'metric': 0.9100621422335713, 'recall': 0.8993944752565441, 'precision': 0.9222968941279623, 'acc': 0.934847728407389}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 5; Loss 1.1509687252533747; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9282, 'recall': 0.9382, 'fscore': 0.9331, 'auc': 0.985, 'acc': 0.9495}, 'politifact': {'precision': 0.8367, 'recall': 0.8166, 'fscore': 0.8192, 'auc': 0.9108, 'acc': 0.8239}, 'COVID': {'precision': 0.9241, 'recall': 0.8765, 'fscore': 0.8974, 'auc': 0.9696, 'acc': 0.9334}, 'auc': 0.9770424738097152, 'metric': 0.9186660914143593, 'recall': 0.9144110200144683, 'precision': 0.9231522898883782, 'acc': 0.9400898652021967}
Max {'gossipcop': {'precision': 0.9282, 'recall': 0.9382, 'fscore': 0.9331, 'auc': 0.985, 'acc': 0.9495}, 'politifact': {'precision': 0.8367, 'recall': 0.8166, 'fscore': 0.8192, 'auc': 0.9108, 'acc': 0.8239}, 'COVID': {'precision': 0.9241, 'recall': 0.8765, 'fscore': 0.8974, 'auc': 0.9696, 'acc': 0.9334}, 'auc': 0.9770424738097152, 'metric': 0.9186660914143593, 'recall': 0.9144110200144683, 'precision': 0.9231522898883782, 'acc': 0.9400898652021967}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 6; Loss 1.0511693086379619; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9349, 'recall': 0.9231, 'fscore': 0.9288, 'auc': 0.9829, 'acc': 0.9476}, 'politifact': {'precision': 0.8046, 'recall': 0.7711, 'fscore': 0.7722, 'auc': 0.8974, 'acc': 0.7817}, 'COVID': {'precision': 0.9312, 'recall': 0.858, 'fscore': 0.888, 'auc': 0.9715, 'acc': 0.9294}, 'auc': 0.9751411663049594, 'metric': 0.9109092273777324, 'recall': 0.896491439594888, 'precision': 0.9282644556346589, 'acc': 0.9360958562156765}
Max {'gossipcop': {'precision': 0.9282, 'recall': 0.9382, 'fscore': 0.9331, 'auc': 0.985, 'acc': 0.9495}, 'politifact': {'precision': 0.8367, 'recall': 0.8166, 'fscore': 0.8192, 'auc': 0.9108, 'acc': 0.8239}, 'COVID': {'precision': 0.9241, 'recall': 0.8765, 'fscore': 0.8974, 'auc': 0.9696, 'acc': 0.9334}, 'auc': 0.9770424738097152, 'metric': 0.9186660914143593, 'recall': 0.9144110200144683, 'precision': 0.9231522898883782, 'acc': 0.9400898652021967}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 7; Loss 0.9987425645192461; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9286, 'recall': 0.9402, 'fscore': 0.9342, 'auc': 0.9844, 'acc': 0.9502}, 'politifact': {'precision': 0.8411, 'recall': 0.8156, 'fscore': 0.8183, 'auc': 0.9216, 'acc': 0.8239}, 'COVID': {'precision': 0.9287, 'recall': 0.8894, 'fscore': 0.9071, 'auc': 0.9726, 'acc': 0.9391}, 'auc': 0.9770474975216354, 'metric': 0.9219599004100836, 'recall': 0.9189564745599228, 'precision': 0.925076278020003, 'acc': 0.9423364952571144}
Max {'gossipcop': {'precision': 0.9286, 'recall': 0.9402, 'fscore': 0.9342, 'auc': 0.9844, 'acc': 0.9502}, 'politifact': {'precision': 0.8411, 'recall': 0.8156, 'fscore': 0.8183, 'auc': 0.9216, 'acc': 0.8239}, 'COVID': {'precision': 0.9287, 'recall': 0.8894, 'fscore': 0.9071, 'auc': 0.9726, 'acc': 0.9391}, 'auc': 0.9770474975216354, 'metric': 0.9219599004100836, 'recall': 0.9189564745599228, 'precision': 0.925076278020003, 'acc': 0.9423364952571144}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 8; Loss 1.0728409712131202; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9307, 'recall': 0.9333, 'fscore': 0.932, 'auc': 0.984, 'acc': 0.9491}, 'politifact': {'precision': 0.8104, 'recall': 0.7701, 'fscore': 0.7708, 'auc': 0.9192, 'acc': 0.7817}, 'COVID': {'precision': 0.9374, 'recall': 0.8884, 'fscore': 0.9099, 'auc': 0.9676, 'acc': 0.9416}, 'auc': 0.975570526217078, 'metric': 0.9189738403538306, 'recall': 0.9111764193660745, 'precision': 0.9275661396852042, 'acc': 0.9408387418871692}
Max {'gossipcop': {'precision': 0.9286, 'recall': 0.9402, 'fscore': 0.9342, 'auc': 0.9844, 'acc': 0.9502}, 'politifact': {'precision': 0.8411, 'recall': 0.8156, 'fscore': 0.8183, 'auc': 0.9216, 'acc': 0.8239}, 'COVID': {'precision': 0.9287, 'recall': 0.8894, 'fscore': 0.9071, 'auc': 0.9726, 'acc': 0.9391}, 'auc': 0.9770474975216354, 'metric': 0.9219599004100836, 'recall': 0.9189564745599228, 'precision': 0.925076278020003, 'acc': 0.9423364952571144}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 9; Loss 0.947817104596358; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9122, 'recall': 0.9477, 'fscore': 0.9279, 'auc': 0.9841, 'acc': 0.9438}, 'politifact': {'precision': 0.7824, 'recall': 0.7675, 'fscore': 0.7691, 'auc': 0.9004, 'acc': 0.7746}, 'COVID': {'precision': 0.9368, 'recall': 0.8865, 'fscore': 0.9086, 'auc': 0.9721, 'acc': 0.9407}, 'auc': 0.9747620435120434, 'metric': 0.9161821762723272, 'recall': 0.9214160839160839, 'precision': 0.9112791487834511, 'acc': 0.9368447329006491}
Max {'gossipcop': {'precision': 0.9286, 'recall': 0.9402, 'fscore': 0.9342, 'auc': 0.9844, 'acc': 0.9502}, 'politifact': {'precision': 0.8411, 'recall': 0.8156, 'fscore': 0.8183, 'auc': 0.9216, 'acc': 0.8239}, 'COVID': {'precision': 0.9287, 'recall': 0.8894, 'fscore': 0.9071, 'auc': 0.9726, 'acc': 0.9391}, 'auc': 0.9770474975216354, 'metric': 0.9219599004100836, 'recall': 0.9189564745599228, 'precision': 0.925076278020003, 'acc': 0.9423364952571144}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 10; Loss 1.0416982057767041; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9304, 'recall': 0.8929, 'fscore': 0.9096, 'auc': 0.9827, 'acc': 0.9354}, 'politifact': {'precision': 0.7291, 'recall': 0.6994, 'fscore': 0.6968, 'auc': 0.9026, 'acc': 0.7113}, 'COVID': {'precision': 0.9451, 'recall': 0.8369, 'fscore': 0.877, 'auc': 0.9686, 'acc': 0.9253}, 'auc': 0.9756931047879324, 'metric': 0.8913163129216433, 'recall': 0.8673257776706053, 'precision': 0.924844659866989, 'acc': 0.9243634548177734}
Max {'gossipcop': {'precision': 0.9286, 'recall': 0.9402, 'fscore': 0.9342, 'auc': 0.9844, 'acc': 0.9502}, 'politifact': {'precision': 0.8411, 'recall': 0.8156, 'fscore': 0.8183, 'auc': 0.9216, 'acc': 0.8239}, 'COVID': {'precision': 0.9287, 'recall': 0.8894, 'fscore': 0.9071, 'auc': 0.9726, 'acc': 0.9391}, 'auc': 0.9770474975216354, 'metric': 0.9219599004100836, 'recall': 0.9189564745599228, 'precision': 0.925076278020003, 'acc': 0.9423364952571144}
100%|███████████████████████████████████████████| 64/64 [01:16<00:00,  1.19s/it]
{'gossipcop': {'precision': 0.9273, 'recall': 0.9342, 'fscore': 0.9307, 'auc': 0.9826, 'acc': 0.9495}, 'politifact': {'precision': 0.7977, 'recall': 0.7915, 'fscore': 0.7907, 'auc': 0.914, 'acc': 0.7919}, 'COVID': {'precision': 0.9442, 'recall': 0.9033, 'fscore': 0.9218, 'auc': 0.9848, 'acc': 0.9489}, 'auc': 0.9797165257967089, 'metric': 0.9210978186471447, 'recall': 0.9167610708080143, 'precision': 0.9256657576000642, 'acc': 0.9426329982838931}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 1; Loss 1.1491354774206108; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9196, 'recall': 0.8413, 'fscore': 0.8716, 'auc': 0.9692, 'acc': 0.9126}, 'politifact': {'precision': 0.8124, 'recall': 0.7616, 'fscore': 0.7609, 'auc': 0.9046, 'acc': 0.7746}, 'COVID': {'precision': 0.9144, 'recall': 0.8082, 'fscore': 0.8466, 'auc': 0.9552, 'acc': 0.9075}, 'auc': 0.9632195630040458, 'metric': 0.8601074073633781, 'recall': 0.8277429467084639, 'precision': 0.9145182278429538, 'acc': 0.9061407888167748}
Max {'gossipcop': {'precision': 0.9196, 'recall': 0.8413, 'fscore': 0.8716, 'auc': 0.9692, 'acc': 0.9126}, 'politifact': {'precision': 0.8124, 'recall': 0.7616, 'fscore': 0.7609, 'auc': 0.9046, 'acc': 0.7746}, 'COVID': {'precision': 0.9144, 'recall': 0.8082, 'fscore': 0.8466, 'auc': 0.9552, 'acc': 0.9075}, 'auc': 0.9632195630040458, 'metric': 0.8601074073633781, 'recall': 0.8277429467084639, 'precision': 0.9145182278429538, 'acc': 0.9061407888167748}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 2; Loss 1.2043553437942116; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9221, 'recall': 0.9029, 'fscore': 0.912, 'auc': 0.9775, 'acc': 0.9358}, 'politifact': {'precision': 0.7884, 'recall': 0.7751, 'fscore': 0.7768, 'auc': 0.8769, 'acc': 0.7817}, 'COVID': {'precision': 0.9113, 'recall': 0.8615, 'fscore': 0.8831, 'auc': 0.9626, 'acc': 0.9245}, 'auc': 0.9696000120569086, 'metric': 0.8982958618417078, 'recall': 0.8852684671650188, 'precision': 0.9138085095591258, 'acc': 0.9268597104343484}
Max {'gossipcop': {'precision': 0.9221, 'recall': 0.9029, 'fscore': 0.912, 'auc': 0.9775, 'acc': 0.9358}, 'politifact': {'precision': 0.7884, 'recall': 0.7751, 'fscore': 0.7768, 'auc': 0.8769, 'acc': 0.7817}, 'COVID': {'precision': 0.9113, 'recall': 0.8615, 'fscore': 0.8831, 'auc': 0.9626, 'acc': 0.9245}, 'auc': 0.9696000120569086, 'metric': 0.8982958618417078, 'recall': 0.8852684671650188, 'precision': 0.9138085095591258, 'acc': 0.9268597104343484}
100%|█████████████████████████████████████████| 195/195 [04:07<00:00,  1.27s/it]
Training Epoch 3; Loss 1.2643231556965748; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9342, 'recall': 0.9228, 'fscore': 0.9283, 'auc': 0.9831, 'acc': 0.9472}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9008, 'acc': 0.8028}, 'COVID': {'precision': 0.9117, 'recall': 0.8716, 'fscore': 0.8895, 'auc': 0.9665, 'acc': 0.9278}, 'auc': 0.9766656954156953, 'metric': 0.9118169861264741, 'recall': 0.9012411917584331, 'precision': 0.9239223973209609, 'acc': 0.9360958562156765}
Max {'gossipcop': {'precision': 0.9342, 'recall': 0.9228, 'fscore': 0.9283, 'auc': 0.9831, 'acc': 0.9472}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9008, 'acc': 0.8028}, 'COVID': {'precision': 0.9117, 'recall': 0.8716, 'fscore': 0.8895, 'auc': 0.9665, 'acc': 0.9278}, 'auc': 0.9766656954156953, 'metric': 0.9118169861264741, 'recall': 0.9012411917584331, 'precision': 0.9239223973209609, 'acc': 0.9360958562156765}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 4; Loss 0.8541102018111791; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9288, 'recall': 0.885, 'fscore': 0.9041, 'auc': 0.9837, 'acc': 0.932}, 'politifact': {'precision': 0.756, 'recall': 0.7201, 'fscore': 0.7181, 'auc': 0.8996, 'acc': 0.7324}, 'COVID': {'precision': 0.9351, 'recall': 0.8572, 'fscore': 0.8887, 'auc': 0.9676, 'acc': 0.9302}, 'auc': 0.9778914811242397, 'metric': 0.8915733132812146, 'recall': 0.8683435817056506, 'precision': 0.9236724014593732, 'acc': 0.9243634548177734}
Max {'gossipcop': {'precision': 0.9342, 'recall': 0.9228, 'fscore': 0.9283, 'auc': 0.9831, 'acc': 0.9472}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9008, 'acc': 0.8028}, 'COVID': {'precision': 0.9117, 'recall': 0.8716, 'fscore': 0.8895, 'auc': 0.9665, 'acc': 0.9278}, 'auc': 0.9766656954156953, 'metric': 0.9118169861264741, 'recall': 0.9012411917584331, 'precision': 0.9239223973209609, 'acc': 0.9360958562156765}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 5; Loss 0.9279303582815024; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9344, 'recall': 0.8681, 'fscore': 0.8951, 'auc': 0.9832, 'acc': 0.9274}, 'politifact': {'precision': 0.7756, 'recall': 0.7171, 'fscore': 0.7118, 'auc': 0.8625, 'acc': 0.7324}, 'COVID': {'precision': 0.9362, 'recall': 0.8847, 'fscore': 0.9072, 'auc': 0.9709, 'acc': 0.9399}, 'auc': 0.9768596106958176, 'metric': 0.8903573630334193, 'recall': 0.8635938295421054, 'precision': 0.9293610600814322, 'acc': 0.9243634548177734}
Max {'gossipcop': {'precision': 0.9342, 'recall': 0.9228, 'fscore': 0.9283, 'auc': 0.9831, 'acc': 0.9472}, 'politifact': {'precision': 0.8204, 'recall': 0.7939, 'fscore': 0.796, 'auc': 0.9008, 'acc': 0.8028}, 'COVID': {'precision': 0.9117, 'recall': 0.8716, 'fscore': 0.8895, 'auc': 0.9665, 'acc': 0.9278}, 'auc': 0.9766656954156953, 'metric': 0.9118169861264741, 'recall': 0.9012411917584331, 'precision': 0.9239223973209609, 'acc': 0.9360958562156765}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 6; Loss 1.0726590497371475; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9257, 'recall': 0.941, 'fscore': 0.933, 'auc': 0.9819, 'acc': 0.9491}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9245, 'acc': 0.7958}, 'COVID': {'precision': 0.9313, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9697, 'acc': 0.9391}, 'auc': 0.975438904964767, 'metric': 0.9196227929373997, 'recall': 0.9167781930712966, 'precision': 0.9225693737011531, 'acc': 0.9405891163255118}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.941, 'fscore': 0.933, 'auc': 0.9819, 'acc': 0.9491}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9245, 'acc': 0.7958}, 'COVID': {'precision': 0.9313, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9697, 'acc': 0.9391}, 'auc': 0.975438904964767, 'metric': 0.9196227929373997, 'recall': 0.9167781930712966, 'precision': 0.9225693737011531, 'acc': 0.9405891163255118}
100%|█████████████████████████████████████████| 195/195 [04:07<00:00,  1.27s/it]
Training Epoch 7; Loss 1.0195960494188165; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9273, 'recall': 0.941, 'fscore': 0.9339, 'auc': 0.9833, 'acc': 0.9498}, 'politifact': {'precision': 0.7941, 'recall': 0.7646, 'fscore': 0.7655, 'auc': 0.901, 'acc': 0.7746}, 'COVID': {'precision': 0.9307, 'recall': 0.8849, 'fscore': 0.9052, 'auc': 0.9744, 'acc': 0.9383}, 'auc': 0.9759576869490663, 'metric': 0.9188352473032879, 'recall': 0.9154288240495136, 'precision': 0.9223888525661981, 'acc': 0.9400898652021967}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.941, 'fscore': 0.933, 'auc': 0.9819, 'acc': 0.9491}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9245, 'acc': 0.7958}, 'COVID': {'precision': 0.9313, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9697, 'acc': 0.9391}, 'auc': 0.975438904964767, 'metric': 0.9196227929373997, 'recall': 0.9167781930712966, 'precision': 0.9225693737011531, 'acc': 0.9405891163255118}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 8; Loss 0.9424027977845609; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9276, 'recall': 0.9328, 'fscore': 0.9302, 'auc': 0.9834, 'acc': 0.9476}, 'politifact': {'precision': 0.784, 'recall': 0.758, 'fscore': 0.7589, 'auc': 0.8968, 'acc': 0.7676}, 'COVID': {'precision': 0.9289, 'recall': 0.8995, 'fscore': 0.9131, 'auc': 0.9736, 'acc': 0.9424}, 'auc': 0.9770274026739544, 'metric': 0.9179883088428122, 'recall': 0.9137401870160491, 'precision': 0.9224673068505143, 'acc': 0.9395906140788817}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.941, 'fscore': 0.933, 'auc': 0.9819, 'acc': 0.9491}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9245, 'acc': 0.7958}, 'COVID': {'precision': 0.9313, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9697, 'acc': 0.9391}, 'auc': 0.975438904964767, 'metric': 0.9196227929373997, 'recall': 0.9167781930712966, 'precision': 0.9225693737011531, 'acc': 0.9405891163255118}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 9; Loss 1.0139940402446646; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.937, 'recall': 0.9151, 'fscore': 0.9254, 'auc': 0.983, 'acc': 0.9457}, 'politifact': {'precision': 0.7548, 'recall': 0.7488, 'fscore': 0.7499, 'auc': 0.8743, 'acc': 0.7535}, 'COVID': {'precision': 0.933, 'recall': 0.8754, 'fscore': 0.9001, 'auc': 0.9746, 'acc': 0.9359}, 'auc': 0.9776426399271227, 'metric': 0.9106603342078342, 'recall': 0.896664925113201, 'precision': 0.9274169771127021, 'acc': 0.935846230654019}
Max {'gossipcop': {'precision': 0.9257, 'recall': 0.941, 'fscore': 0.933, 'auc': 0.9819, 'acc': 0.9491}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9245, 'acc': 0.7958}, 'COVID': {'precision': 0.9313, 'recall': 0.8868, 'fscore': 0.9066, 'auc': 0.9697, 'acc': 0.9391}, 'auc': 0.975438904964767, 'metric': 0.9196227929373997, 'recall': 0.9167781930712966, 'precision': 0.9225693737011531, 'acc': 0.9405891163255118}
100%|███████████████████████████████████████████| 64/64 [01:16<00:00,  1.19s/it]
{'gossipcop': {'precision': 0.9216, 'recall': 0.9355, 'fscore': 0.9282, 'auc': 0.9828, 'acc': 0.9473}, 'politifact': {'precision': 0.8264, 'recall': 0.8145, 'fscore': 0.8132, 'auc': 0.9192, 'acc': 0.815}, 'COVID': {'precision': 0.9385, 'recall': 0.8917, 'fscore': 0.9124, 'auc': 0.9816, 'acc': 0.9432}, 'auc': 0.9792247080343325, 'metric': 0.9182643659346419, 'recall': 0.9149610112532354, 'precision': 0.9217021519986646, 'acc': 0.940426575140966}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.25s/it]
Training Epoch 1; Loss 1.0933855099555772; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.18s/it]
curent {'gossipcop': {'precision': 0.9242, 'recall': 0.8038, 'fscore': 0.8435, 'auc': 0.972, 'acc': 0.8986}, 'politifact': {'precision': 0.7713, 'recall': 0.6772, 'fscore': 0.6599, 'auc': 0.8924, 'acc': 0.6972}, 'COVID': {'precision': 0.9201, 'recall': 0.7781, 'fscore': 0.8232, 'auc': 0.9487, 'acc': 0.8977}, 'auc': 0.963550123248399, 'metric': 0.8295913234230659, 'recall': 0.7889582161133886, 'precision': 0.9176135923608315, 'acc': 0.891163255117324}
Max {'gossipcop': {'precision': 0.9242, 'recall': 0.8038, 'fscore': 0.8435, 'auc': 0.972, 'acc': 0.8986}, 'politifact': {'precision': 0.7713, 'recall': 0.6772, 'fscore': 0.6599, 'auc': 0.8924, 'acc': 0.6972}, 'COVID': {'precision': 0.9201, 'recall': 0.7781, 'fscore': 0.8232, 'auc': 0.9487, 'acc': 0.8977}, 'auc': 0.963550123248399, 'metric': 0.8295913234230659, 'recall': 0.7889582161133886, 'precision': 0.9176135923608315, 'acc': 0.891163255117324}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 2; Loss 1.2387443909278286; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9276, 'recall': 0.8697, 'fscore': 0.8938, 'auc': 0.98, 'acc': 0.9259}, 'politifact': {'precision': 0.7671, 'recall': 0.7267, 'fscore': 0.7246, 'auc': 0.8861, 'acc': 0.7394}, 'COVID': {'precision': 0.928, 'recall': 0.8419, 'fscore': 0.8757, 'auc': 0.964, 'acc': 0.9229}, 'auc': 0.9736484540363851, 'metric': 0.881289343868983, 'recall': 0.8541867615143477, 'precision': 0.9215118538438452, 'acc': 0.918372441337993}
Max {'gossipcop': {'precision': 0.9276, 'recall': 0.8697, 'fscore': 0.8938, 'auc': 0.98, 'acc': 0.9259}, 'politifact': {'precision': 0.7671, 'recall': 0.7267, 'fscore': 0.7246, 'auc': 0.8861, 'acc': 0.7394}, 'COVID': {'precision': 0.928, 'recall': 0.8419, 'fscore': 0.8757, 'auc': 0.964, 'acc': 0.9229}, 'auc': 0.9736484540363851, 'metric': 0.881289343868983, 'recall': 0.8541867615143477, 'precision': 0.9215118538438452, 'acc': 0.918372441337993}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 3; Loss 1.1843792716662087; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9353, 'recall': 0.9018, 'fscore': 0.917, 'auc': 0.9844, 'acc': 0.9403}, 'politifact': {'precision': 0.7693, 'recall': 0.763, 'fscore': 0.7642, 'auc': 0.8827, 'acc': 0.7676}, 'COVID': {'precision': 0.9286, 'recall': 0.8438, 'fscore': 0.8772, 'auc': 0.9705, 'acc': 0.9237}, 'auc': 0.9785211196849128, 'metric': 0.8995888248765362, 'recall': 0.8799751493717012, 'precision': 0.925125752793091, 'acc': 0.9291063404892661}
Max {'gossipcop': {'precision': 0.9353, 'recall': 0.9018, 'fscore': 0.917, 'auc': 0.9844, 'acc': 0.9403}, 'politifact': {'precision': 0.7693, 'recall': 0.763, 'fscore': 0.7642, 'auc': 0.8827, 'acc': 0.7676}, 'COVID': {'precision': 0.9286, 'recall': 0.8438, 'fscore': 0.8772, 'auc': 0.9705, 'acc': 0.9237}, 'auc': 0.9785211196849128, 'metric': 0.8995888248765362, 'recall': 0.8799751493717012, 'precision': 0.925125752793091, 'acc': 0.9291063404892661}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 4; Loss 0.7994573635932727; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9334, 'recall': 0.9356, 'fscore': 0.9345, 'auc': 0.9863, 'acc': 0.951}, 'politifact': {'precision': 0.7833, 'recall': 0.7494, 'fscore': 0.7494, 'auc': 0.9056, 'acc': 0.7606}, 'COVID': {'precision': 0.9249, 'recall': 0.8683, 'fscore': 0.8926, 'auc': 0.9714, 'acc': 0.931}, 'auc': 0.9791745371486751, 'metric': 0.9150014390468684, 'recall': 0.9062993998338826, 'precision': 0.9247135539199212, 'acc': 0.9380928607089366}
Max {'gossipcop': {'precision': 0.9334, 'recall': 0.9356, 'fscore': 0.9345, 'auc': 0.9863, 'acc': 0.951}, 'politifact': {'precision': 0.7833, 'recall': 0.7494, 'fscore': 0.7494, 'auc': 0.9056, 'acc': 0.7606}, 'COVID': {'precision': 0.9249, 'recall': 0.8683, 'fscore': 0.8926, 'auc': 0.9714, 'acc': 0.931}, 'auc': 0.9791745371486751, 'metric': 0.9150014390468684, 'recall': 0.9062993998338826, 'precision': 0.9247135539199212, 'acc': 0.9380928607089366}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 5; Loss 1.0991259293678477; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9325, 'recall': 0.8827, 'fscore': 0.904, 'auc': 0.9842, 'acc': 0.9324}, 'politifact': {'precision': 0.7419, 'recall': 0.7337, 'fscore': 0.7347, 'auc': 0.8518, 'acc': 0.7394}, 'COVID': {'precision': 0.9388, 'recall': 0.887, 'fscore': 0.9097, 'auc': 0.9702, 'acc': 0.9416}, 'auc': 0.9777578503871608, 'metric': 0.8981760695758452, 'recall': 0.8774421938215042, 'precision': 0.9256319905128249, 'acc': 0.9283574638042935}
Max {'gossipcop': {'precision': 0.9334, 'recall': 0.9356, 'fscore': 0.9345, 'auc': 0.9863, 'acc': 0.951}, 'politifact': {'precision': 0.7833, 'recall': 0.7494, 'fscore': 0.7494, 'auc': 0.9056, 'acc': 0.7606}, 'COVID': {'precision': 0.9249, 'recall': 0.8683, 'fscore': 0.8926, 'auc': 0.9714, 'acc': 0.931}, 'auc': 0.9791745371486751, 'metric': 0.9150014390468684, 'recall': 0.9062993998338826, 'precision': 0.9247135539199212, 'acc': 0.9380928607089366}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 6; Loss 1.1155990842061163; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9358, 'recall': 0.9087, 'fscore': 0.9212, 'auc': 0.985, 'acc': 0.943}, 'politifact': {'precision': 0.7333, 'recall': 0.6898, 'fscore': 0.6839, 'auc': 0.8647, 'acc': 0.7042}, 'COVID': {'precision': 0.9346, 'recall': 0.891, 'fscore': 0.9105, 'auc': 0.9711, 'acc': 0.9416}, 'auc': 0.9795067719636685, 'metric': 0.9075758211334368, 'recall': 0.8910939635077566, 'precision': 0.9280084447572132, 'acc': 0.9340988517224164}
Max {'gossipcop': {'precision': 0.9334, 'recall': 0.9356, 'fscore': 0.9345, 'auc': 0.9863, 'acc': 0.951}, 'politifact': {'precision': 0.7833, 'recall': 0.7494, 'fscore': 0.7494, 'auc': 0.9056, 'acc': 0.7606}, 'COVID': {'precision': 0.9249, 'recall': 0.8683, 'fscore': 0.8926, 'auc': 0.9714, 'acc': 0.931}, 'auc': 0.9791745371486751, 'metric': 0.9150014390468684, 'recall': 0.9062993998338826, 'precision': 0.9247135539199212, 'acc': 0.9380928607089366}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 7; Loss 0.9687860916822385; 
100%|███████████████████████████████████████████| 63/63 [01:13<00:00,  1.17s/it]
curent {'gossipcop': {'precision': 0.9335, 'recall': 0.9318, 'fscore': 0.9327, 'auc': 0.9831, 'acc': 0.9498}, 'politifact': {'precision': 0.7915, 'recall': 0.7741, 'fscore': 0.7758, 'auc': 0.901, 'acc': 0.7817}, 'COVID': {'precision': 0.9352, 'recall': 0.8979, 'fscore': 0.9148, 'auc': 0.9733, 'acc': 0.944}, 'auc': 0.9772417477158857, 'metric': 0.9208796447640841, 'recall': 0.9140409399030088, 'precision': 0.928321775235181, 'acc': 0.9420868696954569}
Max {'gossipcop': {'precision': 0.9335, 'recall': 0.9318, 'fscore': 0.9327, 'auc': 0.9831, 'acc': 0.9498}, 'politifact': {'precision': 0.7915, 'recall': 0.7741, 'fscore': 0.7758, 'auc': 0.901, 'acc': 0.7817}, 'COVID': {'precision': 0.9352, 'recall': 0.8979, 'fscore': 0.9148, 'auc': 0.9733, 'acc': 0.944}, 'auc': 0.9772417477158857, 'metric': 0.9208796447640841, 'recall': 0.9140409399030088, 'precision': 0.928321775235181, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.26s/it]
Training Epoch 8; Loss 0.9319408896641853; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9377, 'recall': 0.9026, 'fscore': 0.9184, 'auc': 0.9811, 'acc': 0.9415}, 'politifact': {'precision': 0.7171, 'recall': 0.6842, 'fscore': 0.6799, 'auc': 0.8687, 'acc': 0.6972}, 'COVID': {'precision': 0.9448, 'recall': 0.8936, 'fscore': 0.9161, 'auc': 0.9725, 'acc': 0.9456}, 'auc': 0.9766231613214372, 'metric': 0.9069449210480469, 'recall': 0.8880405514026204, 'precision': 0.9311638697116115, 'acc': 0.9340988517224164}
Max {'gossipcop': {'precision': 0.9335, 'recall': 0.9318, 'fscore': 0.9327, 'auc': 0.9831, 'acc': 0.9498}, 'politifact': {'precision': 0.7915, 'recall': 0.7741, 'fscore': 0.7758, 'auc': 0.901, 'acc': 0.7817}, 'COVID': {'precision': 0.9352, 'recall': 0.8979, 'fscore': 0.9148, 'auc': 0.9733, 'acc': 0.944}, 'auc': 0.9772417477158857, 'metric': 0.9208796447640841, 'recall': 0.9140409399030088, 'precision': 0.928321775235181, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:07<00:00,  1.27s/it]
Training Epoch 9; Loss 1.0002858067170177; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9318, 'recall': 0.9246, 'fscore': 0.9281, 'auc': 0.9816, 'acc': 0.9468}, 'politifact': {'precision': 0.7614, 'recall': 0.7564, 'fscore': 0.7575, 'auc': 0.8881, 'acc': 0.7606}, 'COVID': {'precision': 0.938, 'recall': 0.8902, 'fscore': 0.9113, 'auc': 0.9718, 'acc': 0.9424}, 'auc': 0.9764413029499236, 'metric': 0.9160596305296393, 'recall': 0.9074752833373523, 'precision': 0.9256225133661218, 'acc': 0.9388417373939091}
Max {'gossipcop': {'precision': 0.9335, 'recall': 0.9318, 'fscore': 0.9327, 'auc': 0.9831, 'acc': 0.9498}, 'politifact': {'precision': 0.7915, 'recall': 0.7741, 'fscore': 0.7758, 'auc': 0.901, 'acc': 0.7817}, 'COVID': {'precision': 0.9352, 'recall': 0.8979, 'fscore': 0.9148, 'auc': 0.9733, 'acc': 0.944}, 'auc': 0.9772417477158857, 'metric': 0.9208796447640841, 'recall': 0.9140409399030088, 'precision': 0.928321775235181, 'acc': 0.9420868696954569}
100%|█████████████████████████████████████████| 195/195 [04:04<00:00,  1.26s/it]
Training Epoch 10; Loss 1.0457469701766962; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9332, 'recall': 0.9039, 'fscore': 0.9173, 'auc': 0.9821, 'acc': 0.9403}, 'politifact': {'precision': 0.7484, 'recall': 0.7412, 'fscore': 0.7423, 'auc': 0.8853, 'acc': 0.7465}, 'COVID': {'precision': 0.9385, 'recall': 0.9121, 'fscore': 0.9244, 'auc': 0.9712, 'acc': 0.9497}, 'auc': 0.9779176044262251, 'metric': 0.9116161059018202, 'recall': 0.8986928301583474, 'precision': 0.9268662239630117, 'acc': 0.936345481777334}
Max {'gossipcop': {'precision': 0.9335, 'recall': 0.9318, 'fscore': 0.9327, 'auc': 0.9831, 'acc': 0.9498}, 'politifact': {'precision': 0.7915, 'recall': 0.7741, 'fscore': 0.7758, 'auc': 0.901, 'acc': 0.7817}, 'COVID': {'precision': 0.9352, 'recall': 0.8979, 'fscore': 0.9148, 'auc': 0.9733, 'acc': 0.944}, 'auc': 0.9772417477158857, 'metric': 0.9208796447640841, 'recall': 0.9140409399030088, 'precision': 0.928321775235181, 'acc': 0.9420868696954569}
100%|███████████████████████████████████████████| 64/64 [01:16<00:00,  1.20s/it]
{'gossipcop': {'precision': 0.9369, 'recall': 0.9273, 'fscore': 0.932, 'auc': 0.9836, 'acc': 0.9514}, 'politifact': {'precision': 0.8095, 'recall': 0.8031, 'fscore': 0.8024, 'auc': 0.8931, 'acc': 0.8035}, 'COVID': {'precision': 0.9477, 'recall': 0.9025, 'fscore': 0.9227, 'auc': 0.9848, 'acc': 0.9497}, 'auc': 0.9806271903560526, 'metric': 0.9227519088830938, 'recall': 0.912899336062382, 'precision': 0.9338376107694709, 'acc': 0.9445942632998284}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [04:07<00:00,  1.27s/it]
Training Epoch 1; Loss 1.1692041736382712; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9016, 'recall': 0.8744, 'fscore': 0.8868, 'auc': 0.9678, 'acc': 0.9183}, 'politifact': {'precision': 0.7764, 'recall': 0.76, 'fscore': 0.7613, 'auc': 0.8914, 'acc': 0.7676}, 'COVID': {'precision': 0.873, 'recall': 0.8474, 'fscore': 0.8592, 'auc': 0.9474, 'acc': 0.9067}, 'auc': 0.9598302320285079, 'metric': 0.8738120673830498, 'recall': 0.8611107761969832, 'precision': 0.889106438692276, 'acc': 0.9093859211183225}
Max {'gossipcop': {'precision': 0.9016, 'recall': 0.8744, 'fscore': 0.8868, 'auc': 0.9678, 'acc': 0.9183}, 'politifact': {'precision': 0.7764, 'recall': 0.76, 'fscore': 0.7613, 'auc': 0.8914, 'acc': 0.7676}, 'COVID': {'precision': 0.873, 'recall': 0.8474, 'fscore': 0.8592, 'auc': 0.9474, 'acc': 0.9067}, 'auc': 0.9598302320285079, 'metric': 0.8738120673830498, 'recall': 0.8611107761969832, 'precision': 0.889106438692276, 'acc': 0.9093859211183225}
100%|█████████████████████████████████████████| 195/195 [04:06<00:00,  1.27s/it]
Training Epoch 2; Loss 1.1965449938407313; 
100%|███████████████████████████████████████████| 63/63 [01:14<00:00,  1.19s/it]
curent {'gossipcop': {'precision': 0.9271, 'recall': 0.8845, 'fscore': 0.9032, 'auc': 0.9799, 'acc': 0.9312}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9042, 'acc': 0.7958}, 'COVID': {'precision': 0.9074, 'recall': 0.8605, 'fscore': 0.881, 'auc': 0.9566, 'acc': 0.9229}, 'auc': 0.9720984714519197, 'metric': 0.8919567020349894, 'recall': 0.8720832328590948, 'precision': 0.9181158272154779, 'acc': 0.9238642036944583}
Max {'gossipcop': {'precision': 0.9271, 'recall': 0.8845, 'fscore': 0.9032, 'auc': 0.9799, 'acc': 0.9312}, 'politifact': {'precision': 0.8205, 'recall': 0.7853, 'fscore': 0.7869, 'auc': 0.9042, 'acc': 0.7958}, 'COVID': {'precision': 0.9074, 'recall': 0.8605, 'fscore': 0.881, 'auc': 0.9566, 'acc': 0.9229}, 'auc': 0.9720984714519197, 'metric': 0.8919567020349894, 'recall': 0.8720832328590948, 'precision': 0.9181158272154779, 'acc': 0.9238642036944583}
100%|█████████████████████████████████████████| 195/195 [04:05<00:00,  1.26s/it]
Training Epoch 3; Loss 1.2397400969114063; 
100%|███████████████████████████████████████████| 63/63 [01:15<00:00,  1.20s/it]
curent {'gossipcop': {'precision': 0.9219, 'recall': 0.9408, 'fscore': 0.9308, 'auc': 0.9825, 'acc': 0.9472}, 'politifact': {'precision': 0.8315, 'recall': 0.8331, 'fscore': 0.8309, 'auc': 0.9032, 'acc': 0.831}, 'COVID': {'precision': 0.8918, 'recall': 0.907, 'fscore': 0.8991, 'auc': 0.9682, 'acc': 0.9294}, 'auc': 0.9767119135653617, 'metric': 0.917953119157795, 'recall': 0.9273417195830989, 'precision': 0.9095961736004109, 'acc': 0.9375936095856215}
Max {'gossipcop': {'precision': 0.9219, 'recall': 0.9408, 'fscore': 0.9308, 'auc': 0.9825, 'acc': 0.9472}, 'politifact': {'precision': 0.8315, 'recall': 0.8331, 'fscore': 0.8309, 'auc': 0.9032, 'acc': 0.831}, 'COVID': {'precision': 0.8918, 'recall': 0.907, 'fscore': 0.8991, 'auc': 0.9682, 'acc': 0.9294}, 'auc': 0.9767119135653617, 'metric': 0.917953119157795, 'recall': 0.9273417195830989, 'precision': 0.9095961736004109, 'acc': 0.9375936095856215}
100%|█████████████████████████████████████████| 195/195 [03:57<00:00,  1.22s/it]
Training Epoch 4; Loss 0.8963813204031724; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.04s/it]
curent {'gossipcop': {'precision': 0.9353, 'recall': 0.9126, 'fscore': 0.9232, 'auc': 0.9851, 'acc': 0.9441}, 'politifact': {'precision': 0.7684, 'recall': 0.7438, 'fscore': 0.7443, 'auc': 0.8914, 'acc': 0.7535}, 'COVID': {'precision': 0.9228, 'recall': 0.8829, 'fscore': 0.9008, 'auc': 0.9704, 'acc': 0.9351}, 'auc': 0.9797194424349596, 'metric': 0.9089558090796798, 'recall': 0.8951574766229939, 'precision': 0.925450736322857, 'acc': 0.9345981028457314}
Max {'gossipcop': {'precision': 0.9219, 'recall': 0.9408, 'fscore': 0.9308, 'auc': 0.9825, 'acc': 0.9472}, 'politifact': {'precision': 0.8315, 'recall': 0.8331, 'fscore': 0.8309, 'auc': 0.9032, 'acc': 0.831}, 'COVID': {'precision': 0.8918, 'recall': 0.907, 'fscore': 0.8991, 'auc': 0.9682, 'acc': 0.9294}, 'auc': 0.9767119135653617, 'metric': 0.917953119157795, 'recall': 0.9273417195830989, 'precision': 0.9095961736004109, 'acc': 0.9375936095856215}
100%|█████████████████████████████████████████| 195/195 [03:32<00:00,  1.09s/it]
Training Epoch 5; Loss 1.0236594383533175; 
100%|███████████████████████████████████████████| 63/63 [01:04<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.933, 'recall': 0.9387, 'fscore': 0.9358, 'auc': 0.9842, 'acc': 0.9517}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9218, 'acc': 0.8099}, 'COVID': {'precision': 0.9235, 'recall': 0.8847, 'fscore': 0.9022, 'auc': 0.97, 'acc': 0.9359}, 'auc': 0.9784584907429734, 'metric': 0.9208452597835478, 'recall': 0.9155714974680492, 'precision': 0.9264740201869113, 'acc': 0.9418372441337993}
Max {'gossipcop': {'precision': 0.933, 'recall': 0.9387, 'fscore': 0.9358, 'auc': 0.9842, 'acc': 0.9517}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9218, 'acc': 0.8099}, 'COVID': {'precision': 0.9235, 'recall': 0.8847, 'fscore': 0.9022, 'auc': 0.97, 'acc': 0.9359}, 'auc': 0.9784584907429734, 'metric': 0.9208452597835478, 'recall': 0.9155714974680492, 'precision': 0.9264740201869113, 'acc': 0.9418372441337993}
100%|█████████████████████████████████████████| 195/195 [03:32<00:00,  1.09s/it]
Training Epoch 6; Loss 1.160672818391751; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.9324, 'recall': 0.9169, 'fscore': 0.9243, 'auc': 0.9826, 'acc': 0.9445}, 'politifact': {'precision': 0.843, 'recall': 0.7984, 'fscore': 0.8003, 'auc': 0.9287, 'acc': 0.8099}, 'COVID': {'precision': 0.9392, 'recall': 0.8701, 'fscore': 0.8989, 'auc': 0.973, 'acc': 0.9359}, 'auc': 0.9769530517375346, 'metric': 0.9121058304616063, 'recall': 0.8968153015566809, 'precision': 0.9307083551445355, 'acc': 0.9370943584623065}
Max {'gossipcop': {'precision': 0.933, 'recall': 0.9387, 'fscore': 0.9358, 'auc': 0.9842, 'acc': 0.9517}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9218, 'acc': 0.8099}, 'COVID': {'precision': 0.9235, 'recall': 0.8847, 'fscore': 0.9022, 'auc': 0.97, 'acc': 0.9359}, 'auc': 0.9784584907429734, 'metric': 0.9208452597835478, 'recall': 0.9155714974680492, 'precision': 0.9264740201869113, 'acc': 0.9418372441337993}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 7; Loss 1.0388798392735994; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.9333, 'recall': 0.9238, 'fscore': 0.9284, 'auc': 0.983, 'acc': 0.9472}, 'politifact': {'precision': 0.8267, 'recall': 0.7843, 'fscore': 0.7856, 'auc': 0.9206, 'acc': 0.7958}, 'COVID': {'precision': 0.9327, 'recall': 0.8855, 'fscore': 0.9063, 'auc': 0.9743, 'acc': 0.9391}, 'auc': 0.978903926533237, 'metric': 0.9161432825545435, 'recall': 0.9047534362189534, 'precision': 0.9292912016419594, 'acc': 0.9393409885172241}
Max {'gossipcop': {'precision': 0.933, 'recall': 0.9387, 'fscore': 0.9358, 'auc': 0.9842, 'acc': 0.9517}, 'politifact': {'precision': 0.8307, 'recall': 0.8004, 'fscore': 0.8027, 'auc': 0.9218, 'acc': 0.8099}, 'COVID': {'precision': 0.9235, 'recall': 0.8847, 'fscore': 0.9022, 'auc': 0.97, 'acc': 0.9359}, 'auc': 0.9784584907429734, 'metric': 0.9208452597835478, 'recall': 0.9155714974680492, 'precision': 0.9264740201869113, 'acc': 0.9418372441337993}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 8; Loss 1.0208005040119867; 
100%|███████████████████████████████████████████| 63/63 [01:04<00:00,  1.02s/it]
curent {'gossipcop': {'precision': 0.9208, 'recall': 0.9415, 'fscore': 0.9305, 'auc': 0.9821, 'acc': 0.9468}, 'politifact': {'precision': 0.8367, 'recall': 0.8166, 'fscore': 0.8192, 'auc': 0.9317, 'acc': 0.8239}, 'COVID': {'precision': 0.9185, 'recall': 0.9095, 'fscore': 0.9139, 'auc': 0.9723, 'acc': 0.9416}, 'auc': 0.9766777523243041, 'metric': 0.9212753006274363, 'recall': 0.9254256758567103, 'precision': 0.9173311697762598, 'acc': 0.9408387418871692}
Max {'gossipcop': {'precision': 0.9208, 'recall': 0.9415, 'fscore': 0.9305, 'auc': 0.9821, 'acc': 0.9468}, 'politifact': {'precision': 0.8367, 'recall': 0.8166, 'fscore': 0.8192, 'auc': 0.9317, 'acc': 0.8239}, 'COVID': {'precision': 0.9185, 'recall': 0.9095, 'fscore': 0.9139, 'auc': 0.9723, 'acc': 0.9416}, 'auc': 0.9766777523243041, 'metric': 0.9212753006274363, 'recall': 0.9254256758567103, 'precision': 0.9173311697762598, 'acc': 0.9408387418871692}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 9; Loss 1.0166496347158385; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.04s/it]
curent {'gossipcop': {'precision': 0.9288, 'recall': 0.9479, 'fscore': 0.9378, 'auc': 0.9839, 'acc': 0.9525}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9343, 'acc': 0.8169}, 'COVID': {'precision': 0.9336, 'recall': 0.9124, 'fscore': 0.9224, 'auc': 0.976, 'acc': 0.9481}, 'auc': 0.9792418548884065, 'metric': 0.9282492420181249, 'recall': 0.930429962757549, 'precision': 0.9261249566893954, 'acc': 0.9463305042436345}
Max {'gossipcop': {'precision': 0.9288, 'recall': 0.9479, 'fscore': 0.9378, 'auc': 0.9839, 'acc': 0.9525}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9343, 'acc': 0.8169}, 'COVID': {'precision': 0.9336, 'recall': 0.9124, 'fscore': 0.9224, 'auc': 0.976, 'acc': 0.9481}, 'auc': 0.9792418548884065, 'metric': 0.9282492420181249, 'recall': 0.930429962757549, 'precision': 0.9261249566893954, 'acc': 0.9463305042436345}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 10; Loss 0.8490165426180913; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.9085, 'recall': 0.9454, 'fscore': 0.9246, 'auc': 0.9812, 'acc': 0.9411}, 'politifact': {'precision': 0.8181, 'recall': 0.8034, 'fscore': 0.8056, 'auc': 0.915, 'acc': 0.8099}, 'COVID': {'precision': 0.932, 'recall': 0.8987, 'fscore': 0.914, 'auc': 0.9771, 'acc': 0.9432}, 'auc': 0.976125813841331, 'metric': 0.9170296115700522, 'recall': 0.9249745465262706, 'precision': 0.9098321792155444, 'acc': 0.9370943584623065}
Max {'gossipcop': {'precision': 0.9288, 'recall': 0.9479, 'fscore': 0.9378, 'auc': 0.9839, 'acc': 0.9525}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9343, 'acc': 0.8169}, 'COVID': {'precision': 0.9336, 'recall': 0.9124, 'fscore': 0.9224, 'auc': 0.976, 'acc': 0.9481}, 'auc': 0.9792418548884065, 'metric': 0.9282492420181249, 'recall': 0.930429962757549, 'precision': 0.9261249566893954, 'acc': 0.9463305042436345}
100%|█████████████████████████████████████████| 195/195 [03:31<00:00,  1.08s/it]
Training Epoch 11; Loss 1.0495362883959063; 
100%|███████████████████████████████████████████| 63/63 [01:04<00:00,  1.02s/it]
curent {'gossipcop': {'precision': 0.9359, 'recall': 0.9054, 'fscore': 0.9193, 'auc': 0.9809, 'acc': 0.9419}, 'politifact': {'precision': 0.7725, 'recall': 0.7343, 'fscore': 0.7329, 'auc': 0.8932, 'acc': 0.7465}, 'COVID': {'precision': 0.9378, 'recall': 0.9002, 'fscore': 0.9173, 'auc': 0.9691, 'acc': 0.9456}, 'auc': 0.975496845108914, 'metric': 0.9104437050815191, 'recall': 0.8941165635131152, 'precision': 0.9306017019607384, 'acc': 0.9360958562156765}
Max {'gossipcop': {'precision': 0.9288, 'recall': 0.9479, 'fscore': 0.9378, 'auc': 0.9839, 'acc': 0.9525}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9343, 'acc': 0.8169}, 'COVID': {'precision': 0.9336, 'recall': 0.9124, 'fscore': 0.9224, 'auc': 0.976, 'acc': 0.9481}, 'auc': 0.9792418548884065, 'metric': 0.9282492420181249, 'recall': 0.930429962757549, 'precision': 0.9261249566893954, 'acc': 0.9463305042436345}
100%|█████████████████████████████████████████| 195/195 [03:32<00:00,  1.09s/it]
Training Epoch 12; Loss 0.9668452754998815; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.04s/it]
curent {'gossipcop': {'precision': 0.9266, 'recall': 0.9382, 'fscore': 0.9322, 'auc': 0.9819, 'acc': 0.9487}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9056, 'acc': 0.8169}, 'COVID': {'precision': 0.9209, 'recall': 0.9119, 'fscore': 0.9163, 'auc': 0.9713, 'acc': 0.9432}, 'auc': 0.9772759089569433, 'metric': 0.9227020446178167, 'recall': 0.9237062267234681, 'precision': 0.9217101287244919, 'acc': 0.9423364952571144}
Max {'gossipcop': {'precision': 0.9288, 'recall': 0.9479, 'fscore': 0.9378, 'auc': 0.9839, 'acc': 0.9525}, 'politifact': {'precision': 0.8272, 'recall': 0.81, 'fscore': 0.8124, 'auc': 0.9343, 'acc': 0.8169}, 'COVID': {'precision': 0.9336, 'recall': 0.9124, 'fscore': 0.9224, 'auc': 0.976, 'acc': 0.9481}, 'auc': 0.9792418548884065, 'metric': 0.9282492420181249, 'recall': 0.930429962757549, 'precision': 0.9261249566893954, 'acc': 0.9463305042436345}
100%|███████████████████████████████████████████| 64/64 [01:06<00:00,  1.04s/it]
{'gossipcop': {'precision': 0.9181, 'recall': 0.9388, 'fscore': 0.9278, 'auc': 0.9838, 'acc': 0.9465}, 'politifact': {'precision': 0.8047, 'recall': 0.7972, 'fscore': 0.7964, 'auc': 0.8965, 'acc': 0.7977}, 'COVID': {'precision': 0.9529, 'recall': 0.9242, 'fscore': 0.9376, 'auc': 0.9846, 'acc': 0.9586}, 'auc': 0.9808058546928838, 'metric': 0.9238728389510764, 'recall': 0.9254763564255353, 'precision': 0.9222994478726859, 'acc': 0.9438587889188527}
Some weights of RobertaModel were not initialized from the model checkpoint at /home/xuexinyi/PYPS/M3FEND-main/roberta_base/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
EANNModel(
  (bert): RobertaModel(
    (embeddings): RobertaEmbeddings(
      (word_embeddings): Embedding(50265, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): RobertaEncoder(
      (layer): ModuleList(
        (0): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): RobertaLayer(
          (attention): RobertaAttention(
            (self): RobertaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): RobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): RobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): RobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): RobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (convs): cnn_extractor(
    (convs): ModuleList(
      (0): Conv1d(768, 64, kernel_size=(1,), stride=(1,))
      (1): Conv1d(768, 64, kernel_size=(2,), stride=(1,))
      (2): Conv1d(768, 64, kernel_size=(3,), stride=(1,))
      (3): Conv1d(768, 64, kernel_size=(5,), stride=(1,))
      (4): Conv1d(768, 64, kernel_size=(10,), stride=(1,))
    )
  )
  (classifier): MLP(
    (mlp): Sequential(
      (0): Linear(in_features=320, out_features=384, bias=True)
      (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.2, inplace=False)
      (4): Linear(in_features=384, out_features=1, bias=True)
    )
  )
  (domain_classifier): Sequential(
    (0): MLP(
      (mlp): Sequential(
        (0): Linear(in_features=320, out_features=384, bias=True)
        (1): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
        (3): Dropout(p=0.2, inplace=False)
      )
    )
    (1): ReLU()
    (2): Linear(in_features=384, out_features=3, bias=True)
  )
)
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 1; Loss 1.0957023424979975; 
100%|███████████████████████████████████████████| 63/63 [01:04<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.9074, 'recall': 0.871, 'fscore': 0.8872, 'auc': 0.9696, 'acc': 0.9195}, 'politifact': {'precision': 0.8248, 'recall': 0.7681, 'fscore': 0.7676, 'auc': 0.9204, 'acc': 0.7817}, 'COVID': {'precision': 0.9086, 'recall': 0.7985, 'fscore': 0.8374, 'auc': 0.9554, 'acc': 0.9026}, 'auc': 0.9619381815502505, 'metric': 0.8690673686581867, 'recall': 0.8448259116362564, 'precision': 0.904094102261894, 'acc': 0.9093859211183225}
Max {'gossipcop': {'precision': 0.9074, 'recall': 0.871, 'fscore': 0.8872, 'auc': 0.9696, 'acc': 0.9195}, 'politifact': {'precision': 0.8248, 'recall': 0.7681, 'fscore': 0.7676, 'auc': 0.9204, 'acc': 0.7817}, 'COVID': {'precision': 0.9086, 'recall': 0.7985, 'fscore': 0.8374, 'auc': 0.9554, 'acc': 0.9026}, 'auc': 0.9619381815502505, 'metric': 0.8690673686581867, 'recall': 0.8448259116362564, 'precision': 0.904094102261894, 'acc': 0.9093859211183225}
100%|█████████████████████████████████████████| 195/195 [03:31<00:00,  1.09s/it]
Training Epoch 2; Loss 1.2522445189647184; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.04s/it]
curent {'gossipcop': {'precision': 0.9168, 'recall': 0.9198, 'fscore': 0.9183, 'auc': 0.9803, 'acc': 0.9388}, 'politifact': {'precision': 0.8066, 'recall': 0.7883, 'fscore': 0.7903, 'auc': 0.9062, 'acc': 0.7958}, 'COVID': {'precision': 0.9046, 'recall': 0.8745, 'fscore': 0.8883, 'auc': 0.9637, 'acc': 0.9261}, 'auc': 0.973078430190499, 'metric': 0.904671994160166, 'recall': 0.9001500415293519, 'precision': 0.909468064798812, 'acc': 0.9298552171742387}
Max {'gossipcop': {'precision': 0.9168, 'recall': 0.9198, 'fscore': 0.9183, 'auc': 0.9803, 'acc': 0.9388}, 'politifact': {'precision': 0.8066, 'recall': 0.7883, 'fscore': 0.7903, 'auc': 0.9062, 'acc': 0.7958}, 'COVID': {'precision': 0.9046, 'recall': 0.8745, 'fscore': 0.8883, 'auc': 0.9637, 'acc': 0.9261}, 'auc': 0.973078430190499, 'metric': 0.904671994160166, 'recall': 0.9001500415293519, 'precision': 0.909468064798812, 'acc': 0.9298552171742387}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.10s/it]
Training Epoch 3; Loss 1.1696004237884128; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.04s/it]
curent {'gossipcop': {'precision': 0.9299, 'recall': 0.884, 'fscore': 0.9039, 'auc': 0.9831, 'acc': 0.932}, 'politifact': {'precision': 0.7942, 'recall': 0.756, 'fscore': 0.756, 'auc': 0.9042, 'acc': 0.7676}, 'COVID': {'precision': 0.9336, 'recall': 0.8654, 'fscore': 0.8938, 'auc': 0.9686, 'acc': 0.9326}, 'auc': 0.9773469107520831, 'metric': 0.8946018416160271, 'recall': 0.871705449722691, 'precision': 0.9259796815322561, 'acc': 0.9263604593110335}
Max {'gossipcop': {'precision': 0.9168, 'recall': 0.9198, 'fscore': 0.9183, 'auc': 0.9803, 'acc': 0.9388}, 'politifact': {'precision': 0.8066, 'recall': 0.7883, 'fscore': 0.7903, 'auc': 0.9062, 'acc': 0.7958}, 'COVID': {'precision': 0.9046, 'recall': 0.8745, 'fscore': 0.8883, 'auc': 0.9637, 'acc': 0.9261}, 'auc': 0.973078430190499, 'metric': 0.904671994160166, 'recall': 0.9001500415293519, 'precision': 0.909468064798812, 'acc': 0.9298552171742387}
100%|█████████████████████████████████████████| 195/195 [03:33<00:00,  1.09s/it]
Training Epoch 4; Loss 0.920076866944631; 
100%|███████████████████████████████████████████| 63/63 [01:05<00:00,  1.03s/it]
curent {'gossipcop': {'precision': 0.925, 'recall': 0.8865, 'fscore': 0.9036, 'auc': 0.9819, 'acc': 0.9312}, 'politifact': {'precision': 0.8104, 'recall': 0.7701, 'fscore': 0.7708, 'auc': 0.91, 'acc': 0.7817}, 'COVID': {'precision': 0.9443, 'recall': 0.873, 'fscore': 0.9026, 'auc': 0.9678, 'acc': 0.9383}, 'auc': 0.9772390684028615, 'metric': 0.8976233069256325, 'recall': 0.87625860729309, 'precision': 0.926181299505326, 'acc': 0.9281078382426361}
Max {'gossipcop': {'precision': 0.9168, 'recall': 0.9198, 'fscore': 0.9183, 'auc': 0.9803, 'acc': 0.9388}, 'politifact': {'precision': 0.8066, 'recall': 0.7883, 'fscore': 0.7903, 'auc': 0.9062, 'acc': 0.7958}, 'COVID': {'precision': 0.9046, 'recall': 0.8745, 'fscore': 0.8883, 'auc': 0.9637, 'acc': 0.9261}, 'auc': 0.973078430190499, 'metric': 0.904671994160166, 'recall': 0.9001500415293519, 'precision': 0.909468064798812, 'acc': 0.9298552171742387}
100%|█████████████████████████████████████████| 195/195 [03:32<00:00,  1.09s/it]
Training Epoch 5; Loss 1.0242328484853118; 
100%|███████████████████████████████████████████| 63/63 [00:55<00:00,  1.13it/s]
curent {'gossipcop': {'precision': 0.9261, 'recall': 0.872, 'fscore': 0.8948, 'auc': 0.982, 'acc': 0.9263}, 'politifact': {'precision': 0.7548, 'recall': 0.7488, 'fscore': 0.7499, 'auc': 0.892, 'acc': 0.7535}, 'COVID': {'precision': 0.9454, 'recall': 0.8767, 'fscore': 0.9055, 'auc': 0.9715, 'acc': 0.9399}, 'auc': 0.977687518420277, 'metric': 0.8916585554599021, 'recall': 0.8686828497173325, 'precision': 0.9232871207941046, 'acc': 0.9243634548177734}
Max {'gossipcop': {'precision': 0.9168, 'recall': 0.9198, 'fscore': 0.9183, 'auc': 0.9803, 'acc': 0.9388}, 'politifact': {'precision': 0.8066, 'recall': 0.7883, 'fscore': 0.7903, 'auc': 0.9062, 'acc': 0.7958}, 'COVID': {'precision': 0.9046, 'recall': 0.8745, 'fscore': 0.8883, 'auc': 0.9637, 'acc': 0.9261}, 'auc': 0.973078430190499, 'metric': 0.904671994160166, 'recall': 0.9001500415293519, 'precision': 0.909468064798812, 'acc': 0.9298552171742387}
100%|███████████████████████████████████████████| 64/64 [00:55<00:00,  1.15it/s]
{'gossipcop': {'precision': 0.9238, 'recall': 0.9229, 'fscore': 0.9233, 'auc': 0.9784, 'acc': 0.9447}, 'politifact': {'precision': 0.7791, 'recall': 0.7742, 'fscore': 0.7735, 'auc': 0.8831, 'acc': 0.7746}, 'COVID': {'precision': 0.9219, 'recall': 0.8756, 'fscore': 0.896, 'auc': 0.9708, 'acc': 0.9326}, 'auc': 0.9732741385008558, 'metric': 0.9082441543795665, 'recall': 0.9009671107097164, 'precision': 0.9162150218712022, 'acc': 0.9338073057121844}
best model path: ./param_model/eann/parameter_eann.pkl
best metric: {'gossipcop': {'precision': 0.9181, 'recall': 0.9388, 'fscore': 0.9278, 'auc': 0.9838, 'acc': 0.9465}, 'politifact': {'precision': 0.8047, 'recall': 0.7972, 'fscore': 0.7964, 'auc': 0.8965, 'acc': 0.7977}, 'COVID': {'precision': 0.9529, 'recall': 0.9242, 'fscore': 0.9376, 'auc': 0.9846, 'acc': 0.9586}, 'auc': 0.9808058546928838, 'metric': 0.9238728389510764, 'recall': 0.9254763564255353, 'precision': 0.9222994478726859, 'acc': 0.9438587889188527}

Process finished with exit code 0
